{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFL Bike data prep\n",
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data prep as part of my MSc thesis, \"Using machine learning to analyse and predict Transport for London bike sharing habits in the post COVID-19 era\"."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code for downloading the data has been adopted from [Markus Hauru's](https://github.com/mhauru) analysis, 'Predicting Boris Bike usage'.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import requests\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model, svm, neighbors, tree\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from timeit import default_timer as timer\n",
    "from IPython.display import set_matplotlib_formats\n",
    "from urllib.parse import urlparse\n",
    "import openpyxl\n",
    "\n",
    "try:\n",
    "    import xlrd\n",
    "except Exception as e:\n",
    "    msg = (\n",
    "        \"Please install the package xlrd: `pip install --user xlrd`\"\n",
    "        \"It's an optional requirement for pandas, and we'll be needing it.\"\n",
    "    )\n",
    "    print(msg)\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EMoses\\AppData\\Local\\Temp\\ipykernel_8052\\99259732.py:4: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats(\"svg\")\n"
     ]
    }
   ],
   "source": [
    "# For pretty and exportable matplotlib plots.\n",
    "# If you are running this yourself and want interactivity,\n",
    "# try `%matplotlib widget` instead.\n",
    "set_matplotlib_formats(\"svg\")\n",
    "%matplotlib inline\n",
    "# %matplotlib widget\n",
    "# Set a consistent plotting style across the notebook using Seaborn.\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(\"notebook\")\n",
    "# Make pandas cooperate with pyplot\n",
    "pd.plotting.register_matplotlib_converters()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Processing and cleaning the bike data\n",
    "Before getting anywhere with it, we'll need to process the bike data quite a bit. The data comes in CSV files, each of which covers a period of time. Up first, we need to download the data from the TfL website. If you are running this code yourself, here's a script that does that. Be warned though, it's almost seven gigs of data. You can run it repeatedly, and it'll only download data that it doesn't have already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikefolder = \"data/bikes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(datafolder, url, verbosity=0):\n",
    "    \"\"\"Download the data from the given URL into the datafolder, unless it's\n",
    "    already there. Return path to downloaded file.\n",
    "    \"\"\"\n",
    "    # data folder variable for where the folder for where the downloaded file should be stores \n",
    "    # using the path() function to converted the data folder string into a path\n",
    "    datafolder = Path(datafolder)\n",
    "    datafolder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # using the url parse function to extract the file from the url and create a filepath for it to be stored\n",
    "    a = urlparse(url)\n",
    "    filename = Path(os.path.basename(a.path))\n",
    "    filepath = datafolder / filename\n",
    "    # Don't redownload if we already have this file.\n",
    "    if filepath.exists():\n",
    "        if verbosity > 1:\n",
    "            print(\"Already have {}\".format(filename))\n",
    "    else:\n",
    "        if verbosity > 0:\n",
    "            print(\"Downloading {}\".format(filename))\n",
    "        # sends a GET request to the URL using the requests module and raises an exception if there is an error\n",
    "        rqst = requests.get(url)\n",
    "        rqst.raise_for_status()\n",
    "        with open(filepath, \"wb\") as f:\n",
    "            f.write(rqst.content)\n",
    "    return filepath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust whether to print progress reports of the downloads.\n",
    "# verbosity=0 is silence, verbosity=1 reports only when actually doing things,\n",
    "# verbosity>1 also reports when there's nothing to do.\n",
    "verbosity = 1\n",
    "\n",
    "# Most files are individual CSV files, listed in bike_data_urls.txt. Download them.\n",
    "urlsfile = \"data/bikes/bike_data_urls.txt\"\n",
    "with open(urlsfile, \"r\") as f:\n",
    "    urls = f.read().splitlines()\n",
    "# There are a few comments in the file, marked by lines starting with #.\n",
    "# Filter them out.\n",
    "urls = [u for u in urls if u[0] != \"#\"]\n",
    "for url in urls:\n",
    "    download_file(bikefolder, url, verbosity)\n",
    "\n",
    "# The early years come in zips. Download and unzip them.\n",
    "zipsfolder = Path(\"data/bikes/bikezips\")\n",
    "bikezipurls = [\n",
    "    \"https://cycling.data.tfl.gov.uk/usage-stats/cyclehireusagestats-2012.zip\",\n",
    "    \"https://cycling.data.tfl.gov.uk/usage-stats/cyclehireusagestats-2013.zip\",\n",
    "    \"https://cycling.data.tfl.gov.uk/usage-stats/cyclehireusagestats-2014.zip\",\n",
    "    \"https://cycling.data.tfl.gov.uk/usage-stats/2015TripDatazip.zip\",\n",
    "    \"https://cycling.data.tfl.gov.uk/usage-stats/2016TripDataZip.zip\",\n",
    "]\n",
    "# A list of CSV files that are already there. Only unzip if some of the files\n",
    "# in the zip aren't present already.\n",
    "current_csvs = sorted(os.listdir(bikefolder))\n",
    "for url in bikezipurls:\n",
    "    zippath = download_file(zipsfolder, url, verbosity)\n",
    "    with zipfile.ZipFile(zippath, \"r\") as z:\n",
    "        namelist = z.namelist()\n",
    "        has_been_extracted = any(name not in current_csvs for name in namelist)\n",
    "        if has_been_extracted:\n",
    "            if verbosity > 0:\n",
    "                print(\"Unzipping {}\".format(zippath))\n",
    "            z.extractall(bikefolder)\n",
    "        else:\n",
    "            if verbosity > 1:\n",
    "                print(\"{} has already been extracted.\".format(zippath))\n",
    "\n",
    "# Finally, there's an odd one out: One week's data comes in as an .xlsx.\n",
    "# Download it and use pandas to convert it to csv.\n",
    "xlsxurl = \"https://cycling.data.tfl.gov.uk/usage-stats/49JourneyDataExtract15Mar2017-21Mar2017.xlsx\"\n",
    "xlsxfile = download_file(bikefolder, xlsxurl)\n",
    "csvfile = xlsxfile.with_suffix(\".csv\")\n",
    "if not csvfile.exists():\n",
    "    if verbosity > 0:\n",
    "        print(\"Converting .xlsx to .csv.\")\n",
    "    pd.read_excel(xlsxfile).to_csv(csvfile, date_format=\"%d/%m/%Y %H:%M:%S\")\n",
    "else:\n",
    "    if verbosity > 1:\n",
    "        print(\"Already have {}\".format(csvfile))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we have now lists on each line of the CSV file a single bike trip, with starting point and time, end point and time, and things like bike ID number. Here's an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rental Id</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Bike Id</th>\n",
       "      <th>End Date</th>\n",
       "      <th>EndStation Id</th>\n",
       "      <th>EndStation Name</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>StartStation Id</th>\n",
       "      <th>StartStation Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62857677</td>\n",
       "      <td>3780.0</td>\n",
       "      <td>7851</td>\n",
       "      <td>06/03/2017 19:20</td>\n",
       "      <td>43.0</td>\n",
       "      <td>Crawford Street, Marylebone</td>\n",
       "      <td>06/03/2017 18:17</td>\n",
       "      <td>811</td>\n",
       "      <td>Westferry Circus, Canary Wharf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62863035</td>\n",
       "      <td>540.0</td>\n",
       "      <td>4089</td>\n",
       "      <td>06/03/2017 22:17</td>\n",
       "      <td>295.0</td>\n",
       "      <td>Swan Street, The Borough</td>\n",
       "      <td>06/03/2017 22:08</td>\n",
       "      <td>272</td>\n",
       "      <td>Baylis Road, Waterloo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62775896</td>\n",
       "      <td>600.0</td>\n",
       "      <td>4895</td>\n",
       "      <td>02/03/2017 21:27</td>\n",
       "      <td>295.0</td>\n",
       "      <td>Swan Street, The Borough</td>\n",
       "      <td>02/03/2017 21:17</td>\n",
       "      <td>197</td>\n",
       "      <td>Stamford Street, South Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62747748</td>\n",
       "      <td>420.0</td>\n",
       "      <td>4347</td>\n",
       "      <td>01/03/2017 21:08</td>\n",
       "      <td>295.0</td>\n",
       "      <td>Swan Street, The Borough</td>\n",
       "      <td>01/03/2017 21:01</td>\n",
       "      <td>803</td>\n",
       "      <td>Southwark Street, Bankside</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62843939</td>\n",
       "      <td>420.0</td>\n",
       "      <td>3192</td>\n",
       "      <td>06/03/2017 09:28</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Bankside Mix, Bankside</td>\n",
       "      <td>06/03/2017 09:21</td>\n",
       "      <td>197</td>\n",
       "      <td>Stamford Street, South Bank</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rental Id  Duration  Bike Id          End Date  EndStation Id  \\\n",
       "0   62857677    3780.0     7851  06/03/2017 19:20           43.0   \n",
       "1   62863035     540.0     4089  06/03/2017 22:17          295.0   \n",
       "2   62775896     600.0     4895  02/03/2017 21:27          295.0   \n",
       "3   62747748     420.0     4347  01/03/2017 21:08          295.0   \n",
       "4   62843939     420.0     3192  06/03/2017 09:28          193.0   \n",
       "\n",
       "               EndStation Name        Start Date  StartStation Id  \\\n",
       "0  Crawford Street, Marylebone  06/03/2017 18:17              811   \n",
       "1     Swan Street, The Borough  06/03/2017 22:08              272   \n",
       "2     Swan Street, The Borough  02/03/2017 21:17              197   \n",
       "3     Swan Street, The Borough  01/03/2017 21:01              803   \n",
       "4       Bankside Mix, Bankside  06/03/2017 09:21              197   \n",
       "\n",
       "                StartStation Name  \n",
       "0  Westferry Circus, Canary Wharf  \n",
       "1           Baylis Road, Waterloo  \n",
       "2     Stamford Street, South Bank  \n",
       "3      Southwark Street, Bankside  \n",
       "4     Stamford Street, South Bank  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_file  = Path(bikefolder) / Path(\"47JourneyDataExtract01Mar2017-07Mar2017.csv\")\n",
    "pd.read_csv(example_file, encoding=\"ISO-8859-2\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/bikes'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikefolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/bikes\\\\01aJourneyDataExtract10Jan16-23Jan16.csv',\n",
       " 'data/bikes\\\\01bJourneyDataExtract24Jan16-06Feb16.csv',\n",
       " 'data/bikes\\\\02aJourneyDataExtract07Feb16-20Feb2016.csv',\n",
       " 'data/bikes\\\\02bJourneyDataExtract21Feb16-05Mar2016.csv',\n",
       " 'data/bikes\\\\03JourneyDataExtract06Mar2016-31Mar2016.csv',\n",
       " 'data/bikes\\\\04JourneyDataExtract01Apr2016-30Apr2016.csv',\n",
       " 'data/bikes\\\\05JourneyDataExtract01May2016-17May2016.csv',\n",
       " 'data/bikes\\\\06JourneyDataExtract18May2016-24May2016.csv',\n",
       " 'data/bikes\\\\07JourneyDataExtract25May2016-31May2016.csv',\n",
       " 'data/bikes\\\\08JourneyDataExtract01Jun2016-07Jun2016.csv',\n",
       " 'data/bikes\\\\09JourneyDataExtract08Jun2016-14Jun2016.csv',\n",
       " 'data/bikes\\\\1. Journey Data Extract 01Jan-05Jan13.csv',\n",
       " 'data/bikes\\\\1. Journey Data Extract 04Jan-31Jan 12.csv',\n",
       " 'data/bikes\\\\1. Journey Data Extract 05Jan14-02Feb14.csv',\n",
       " 'data/bikes\\\\10. Journey Data Extract 18Aug-13Sep13.csv',\n",
       " 'data/bikes\\\\10. Journey Data Extract 21Aug-22 Aug12.csv',\n",
       " 'data/bikes\\\\10a Journey Data Extract 20Sep15-03Oct15.csv',\n",
       " 'data/bikes\\\\10a. Journey Data Extract 14Sep14-27Sep14.csv',\n",
       " 'data/bikes\\\\10b Journey Data Extract 04Oct15-17Oct15.csv',\n",
       " 'data/bikes\\\\10b. Journey Data Extract 28Sep14-11Oct14.csv',\n",
       " 'data/bikes\\\\10JourneyDataExtract15Jun2016-21Jun2016.csv',\n",
       " 'data/bikes\\\\11. Journey Data Extract 14Sep13-12Oct13.csv',\n",
       " 'data/bikes\\\\11. Journey Data Extract 23Aug-25 Aug12.csv',\n",
       " 'data/bikes\\\\11a Journey Data Extract 18Oct15-31Oct15.csv',\n",
       " 'data/bikes\\\\11a. Journey Data Extract 12Oct14-08Nov14.csv',\n",
       " 'data/bikes\\\\11b Journey Data Extract 01Nov15-14Nov15.csv',\n",
       " 'data/bikes\\\\11b. Journey Data Extract 12Oct14-08Nov14.csv',\n",
       " 'data/bikes\\\\11JourneyDataExtract22Jun2016-28Jun2016.csv',\n",
       " 'data/bikes\\\\12. Journey Data Extract 13Oct13-09Nov13.csv',\n",
       " 'data/bikes\\\\12. Journey Data Extract 26Aug-27 Aug12.csv',\n",
       " 'data/bikes\\\\12a Journey Data Extract 15Nov15-27Nov15.csv',\n",
       " 'data/bikes\\\\12a. Journey Data Extract 09Nov14-06Dec14.csv',\n",
       " 'data/bikes\\\\12b Journey Data Extract 28Nov15-12Dec15.csv',\n",
       " 'data/bikes\\\\12b. Journey Data Extract 09Nov14-06Dec14.csv',\n",
       " 'data/bikes\\\\12JourneyDataExtract29Jun2016-05Jul2016.csv',\n",
       " 'data/bikes\\\\13. Journey Data Extract 10Nov13-07Dec13.csv',\n",
       " 'data/bikes\\\\13. Journey Data Extract 28Aug-29 Aug12.csv',\n",
       " 'data/bikes\\\\13a Journey Data Extract 13Dec15-24Dec15.csv',\n",
       " 'data/bikes\\\\13a. Journey Data Extract 07Dec14-21Dec14.csv',\n",
       " 'data/bikes\\\\13b Journey Data Extract 25Dec15-09Jan16.csv',\n",
       " 'data/bikes\\\\13b. Journey Data Extract 22Dec14-03Jan15.csv',\n",
       " 'data/bikes\\\\13JourneyDataExtract06Jul2016-12Jul2016.csv',\n",
       " 'data/bikes\\\\14. Journey Data Extract 08Dec13-04Jan14.csv',\n",
       " 'data/bikes\\\\14. Journey Data Extract 30Aug-31 Aug12.csv',\n",
       " 'data/bikes\\\\142JourneyDataExtract26Dec2018-01Jan2019.csv',\n",
       " 'data/bikes\\\\143JourneyDataExtract02Jan2019-08Jan2019.csv',\n",
       " 'data/bikes\\\\144JourneyDataExtract09Jan2019-15Jan2019.csv',\n",
       " 'data/bikes\\\\145JourneyDataExtract16Jan2019-22Jan2019.csv',\n",
       " 'data/bikes\\\\146JourneyDataExtract23Jan2019-29Jan2019.csv',\n",
       " 'data/bikes\\\\147JourneyDataExtract30Jan2019-05Feb2019.csv',\n",
       " 'data/bikes\\\\148JourneyDataExtract06Feb2019-12Feb2019.csv',\n",
       " 'data/bikes\\\\149JourneyDataExtract13Feb2019-19Feb2019.csv',\n",
       " 'data/bikes\\\\14JourneyDataExtract13Jul2016-19Jul2016.csv',\n",
       " 'data/bikes\\\\15. Journey Data Extract 01Sep-30Sep12.csv',\n",
       " 'data/bikes\\\\150JourneyDataExtract20Feb2019-26Feb2019.csv',\n",
       " 'data/bikes\\\\151JourneyDataExtract27Feb2019-05Mar2019.csv',\n",
       " 'data/bikes\\\\152JourneyDataExtract06Mar2019-12Mar2019.csv',\n",
       " 'data/bikes\\\\153JourneyDataExtract13Mar2019-19Mar2019.csv',\n",
       " 'data/bikes\\\\154JourneyDataExtract20Mar2019-26Mar2019.csv',\n",
       " 'data/bikes\\\\155JourneyDataExtract27Mar2019-02Apr2019.csv',\n",
       " 'data/bikes\\\\156JourneyDataExtract03Apr2019-09Apr2019.csv',\n",
       " 'data/bikes\\\\157JourneyDataExtract10Apr2019-16Apr2019.csv',\n",
       " 'data/bikes\\\\158JourneyDataExtract17Apr2019-23Apr2019.csv',\n",
       " 'data/bikes\\\\159JourneyDataExtract24Apr2019-30Apr2019.csv',\n",
       " 'data/bikes\\\\15JourneyDataExtract20Jul2016-26Jul2016.csv',\n",
       " 'data/bikes\\\\16. Journey Data Extract 01Oct-31Oct12.csv',\n",
       " 'data/bikes\\\\160JourneyDataExtract01May2019-07May2019.csv',\n",
       " 'data/bikes\\\\161JourneyDataExtract08May2019-14May2019.csv',\n",
       " 'data/bikes\\\\162JourneyDataExtract15May2019-21May2019.csv',\n",
       " 'data/bikes\\\\163JourneyDataExtract22May2019-28May2019.csv',\n",
       " 'data/bikes\\\\164JourneyDataExtract29May2019-04Jun2019.csv',\n",
       " 'data/bikes\\\\165JourneyDataExtract05Jun2019-11Jun2019.csv',\n",
       " 'data/bikes\\\\166JourneyDataExtract12Jun2019-18Jun2019.csv',\n",
       " 'data/bikes\\\\167JourneyDataExtract19Jun2019-25Jun2019.csv',\n",
       " 'data/bikes\\\\168JourneyDataExtract26Jun2019-02Jul2019.csv',\n",
       " 'data/bikes\\\\169JourneyDataExtract03Jul2019-09Jul2019.csv',\n",
       " 'data/bikes\\\\16JourneyDataExtract27Jul2016-02Aug2016.csv',\n",
       " 'data/bikes\\\\17. Journey Data Extract 01Nov-30Nov12.csv',\n",
       " 'data/bikes\\\\170JourneyDataExtract10Jul2019-16Jul2019.csv',\n",
       " 'data/bikes\\\\171JourneyDataExtract17Jul2019-23Jul2019.csv',\n",
       " 'data/bikes\\\\172JourneyDataExtract24Jul2019-30Jul2019.csv',\n",
       " 'data/bikes\\\\173JourneyDataExtract31Jul2019-06Aug2019.csv',\n",
       " 'data/bikes\\\\174JourneyDataExtract07Aug2019-13Aug2019.csv',\n",
       " 'data/bikes\\\\175JourneyDataExtract14Aug2019-20Aug2019.csv',\n",
       " 'data/bikes\\\\176JourneyDataExtract21Aug2019-27Aug2019.csv',\n",
       " 'data/bikes\\\\177JourneyDataExtract28Aug2019-03Sep2019.csv',\n",
       " 'data/bikes\\\\178JourneyDataExtract04Sep2019-10Sep2019.csv',\n",
       " 'data/bikes\\\\179JourneyDataExtract11Sep2019-17Sep2019.csv',\n",
       " 'data/bikes\\\\17JourneyDataExtract03Aug2016-09Aug2016.csv',\n",
       " 'data/bikes\\\\18. Journey Data Extract 01Dec-31Dec12.csv',\n",
       " 'data/bikes\\\\180JourneyDataExtract18Sep2019-24Sep2019.csv',\n",
       " 'data/bikes\\\\181JourneyDataExtract25Sep2019-01Oct2019.csv',\n",
       " 'data/bikes\\\\182JourneyDataExtract02Oct2019-08Oct2019.csv',\n",
       " 'data/bikes\\\\183JourneyDataExtract09Oct2019-15Oct2019.csv',\n",
       " 'data/bikes\\\\184JourneyDataExtract16Oct2019-22Oct2019.csv',\n",
       " 'data/bikes\\\\185JourneyDataExtract23Oct2019-29Oct2019.csv',\n",
       " 'data/bikes\\\\186JourneyDataExtract30Oct2019-05Nov2019.csv',\n",
       " 'data/bikes\\\\187JourneyDataExtract06Nov2019-12Nov2019.csv',\n",
       " 'data/bikes\\\\188JourneyDataExtract13Nov2019-19Nov2019.csv',\n",
       " 'data/bikes\\\\189JourneyDataExtract20Nov2019-26Nov2019.csv',\n",
       " 'data/bikes\\\\18JourneyDataExtract10Aug2016-16Aug2016.csv',\n",
       " 'data/bikes\\\\190JourneyDataExtract27Nov2019-03Dec2019.csv',\n",
       " 'data/bikes\\\\191JourneyDataExtract04Dec2019-10Dec2019.csv',\n",
       " 'data/bikes\\\\192JourneyDataExtract11Dec2019-17Dec2019.csv',\n",
       " 'data/bikes\\\\193JourneyDataExtract18Dec2019-24Dec2019.csv',\n",
       " 'data/bikes\\\\194JourneyDataExtract25Dec2019-31Dec2019.csv',\n",
       " 'data/bikes\\\\19JourneyDataExtract17Aug2016-23Aug2016.csv',\n",
       " 'data/bikes\\\\1a.JourneyDataExtract04Jan15-17Jan15.csv',\n",
       " 'data/bikes\\\\1b.JourneyDataExtract18Jan15-31Jan15.csv',\n",
       " 'data/bikes\\\\2. Journey Data Extract 03Feb14-01Mar14.csv',\n",
       " 'data/bikes\\\\2. Journey Data Extract 06Jan-02Feb13.csv',\n",
       " 'data/bikes\\\\2. Journey Data Extract_01Feb-29Feb 12.csv',\n",
       " 'data/bikes\\\\20JourneyDataExtract24Aug2016-30Aug2016.csv',\n",
       " 'data/bikes\\\\21JourneyDataExtract31Aug2016-06Sep2016.csv',\n",
       " 'data/bikes\\\\22JourneyDataExtract07Sep2016-13Sep2016.csv',\n",
       " 'data/bikes\\\\23JourneyDataExtract14Sep2016-20Sep2016.csv',\n",
       " 'data/bikes\\\\24JourneyDataExtract21Sep2016-27Sep2016.csv',\n",
       " 'data/bikes\\\\25JourneyDataExtract28Sep2016-04Oct2016.csv',\n",
       " 'data/bikes\\\\26JourneyDataExtract05Oct2016-11Oct2016.csv',\n",
       " 'data/bikes\\\\27JourneyDataExtract12Oct2016-18Oct2016.csv',\n",
       " 'data/bikes\\\\28JourneyDataExtract19Oct2016-25Oct2016.csv',\n",
       " 'data/bikes\\\\298JourneyDataExtract29Dec2021-04Jan2022.csv',\n",
       " 'data/bikes\\\\299JourneyDataExtract05Jan2022-11Jan2022.csv',\n",
       " 'data/bikes\\\\29JourneyDataExtract26Oct2016-01Nov2016.csv',\n",
       " 'data/bikes\\\\2a.JourneyDataExtract01Feb15-14Feb15.csv',\n",
       " 'data/bikes\\\\2b.JourneyDataExtract15Feb15-28Feb15.csv',\n",
       " 'data/bikes\\\\3. Journey Data Extract 02Mar14-31Mar14.csv',\n",
       " 'data/bikes\\\\3. Journey Data Extract 03Feb-02Mar13.csv',\n",
       " 'data/bikes\\\\3. Journey Data Extract_01Mar-31Mar12.csv',\n",
       " 'data/bikes\\\\300JourneyDataExtract12Jan2022-18Jan2022.csv',\n",
       " 'data/bikes\\\\301JourneyDataExtract19Jan2022-25Jan2022.csv',\n",
       " 'data/bikes\\\\302JourneyDataExtract26Jan2022-01Feb2022.csv',\n",
       " 'data/bikes\\\\303JourneyDataExtract02Feb2022-08Feb2022.csv',\n",
       " 'data/bikes\\\\304JourneyDataExtract09Feb2022-15Feb2022.csv',\n",
       " 'data/bikes\\\\305JourneyDataExtract16Feb2022-22Feb2022.csv',\n",
       " 'data/bikes\\\\306JourneyDataExtract23Feb2022-01Mar2022.csv',\n",
       " 'data/bikes\\\\307JourneyDataExtract02Mar2022-08Mar2022.csv',\n",
       " 'data/bikes\\\\308JourneyDataExtract09Mar2022-15Mar2022.csv',\n",
       " 'data/bikes\\\\309JourneyDataExtract16Mar2022-22Mar2022.csv',\n",
       " 'data/bikes\\\\30JourneyDataExtract02Nov2016-08Nov2016.csv',\n",
       " 'data/bikes\\\\310JourneyDataExtract23Mar2022-29Mar2022.csv',\n",
       " 'data/bikes\\\\311JourneyDataExtract30Mar2022-05Apr2022.csv',\n",
       " 'data/bikes\\\\312JourneyDataExtract06Apr2022-12Apr2022.csv',\n",
       " 'data/bikes\\\\313JourneyDataExtract13Apr2022-19Apr2022.csv',\n",
       " 'data/bikes\\\\314JourneyDataExtract20Apr2022-26Apr2022.csv',\n",
       " 'data/bikes\\\\315JourneyDataExtract27Apr2022-03May2022.csv',\n",
       " 'data/bikes\\\\316JourneyDataExtract04May2022-10May2022.csv',\n",
       " 'data/bikes\\\\317JourneyDataExtract11May2022-17May2022.csv',\n",
       " 'data/bikes\\\\318JourneyDataExtract18May2022-24May2022.csv',\n",
       " 'data/bikes\\\\319JourneyDataExtract25May2022-31May2022.csv',\n",
       " 'data/bikes\\\\31JourneyDataExtract09Nov2016-15Nov2016.csv',\n",
       " 'data/bikes\\\\320JourneyDataExtract01Jun2022-07Jun2022.csv',\n",
       " 'data/bikes\\\\321JourneyDataExtract08Jun2022-14Jun2022.csv',\n",
       " 'data/bikes\\\\322JourneyDataExtract15Jun2022-21Jun2022.csv',\n",
       " 'data/bikes\\\\323JourneyDataExtract22Jun2022-28Jun2022.csv',\n",
       " 'data/bikes\\\\324JourneyDataExtract29Jun2022-05Jul2022.csv',\n",
       " 'data/bikes\\\\325JourneyDataExtract06Jul2022-12Jul2022.csv',\n",
       " 'data/bikes\\\\326JourneyDataExtract13Jul2022-19Jul2022.csv',\n",
       " 'data/bikes\\\\327JourneyDataExtract20Jul2022-26Jul2022.csv',\n",
       " 'data/bikes\\\\328JourneyDataExtract27Jul2022-02Aug2022.csv',\n",
       " 'data/bikes\\\\329JourneyDataExtract03Aug2022-09Aug2022.csv',\n",
       " 'data/bikes\\\\32JourneyDataExtract16Nov2016-22Nov2016.csv',\n",
       " 'data/bikes\\\\330JourneyDataExtract10Aug2022-16Aug2022.csv',\n",
       " 'data/bikes\\\\331JourneyDataExtract17Aug2022-23Aug2022.csv',\n",
       " 'data/bikes\\\\332JourneyDataExtract24Aug2022-30Aug2022.csv',\n",
       " 'data/bikes\\\\333JourneyDataExtract31Aug2022-06Sep2022.csv',\n",
       " 'data/bikes\\\\334JourneyDataExtract07Sep2022-11Sep2022.csv',\n",
       " 'data/bikes\\\\335JourneyDataExtract12Sep2022-18Sep2022.csv',\n",
       " 'data/bikes\\\\336JourneyDataExtract19Sep2022-25Sep2022.csv',\n",
       " 'data/bikes\\\\337JourneyDataExtract26Sep2022-02Oct2022.csv',\n",
       " 'data/bikes\\\\338JourneyDataExtract03Oct2022-09Oct2022.csv',\n",
       " 'data/bikes\\\\339JourneyDataExtract10Oct2022-16Oct2022.csv',\n",
       " 'data/bikes\\\\33JourneyDataExtract23Nov2016-29Nov2016.csv',\n",
       " 'data/bikes\\\\340JourneyDataExtract17Oct2022-23Oct2022.csv',\n",
       " 'data/bikes\\\\341JourneyDataExtract24Oct2022-30Oct2022.csv',\n",
       " 'data/bikes\\\\342JourneyDataExtract31Oct2022-06Nov2022.csv',\n",
       " 'data/bikes\\\\343JourneyDataExtract07Nov2022-13Nov2022.csv',\n",
       " 'data/bikes\\\\344JourneyDataExtract14Nov2022-20Nov2022.csv',\n",
       " 'data/bikes\\\\345JourneyDataExtract21Nov2022-27Nov2022.csv',\n",
       " 'data/bikes\\\\346JourneyDataExtract28Nov2022-04Dec2022.csv',\n",
       " 'data/bikes\\\\347JourneyDataExtract05Dec2022-11Dec2022.csv',\n",
       " 'data/bikes\\\\348JourneyDataExtract12Dec2022-18Dec2022.csv',\n",
       " 'data/bikes\\\\349JourneyDataExtract19Dec2022-25Dec2022.csv',\n",
       " 'data/bikes\\\\34JourneyDataExtract30Nov2016-06Dec2016.csv',\n",
       " 'data/bikes\\\\350JourneyDataExtract26Dec2022-01Jan2023.csv',\n",
       " 'data/bikes\\\\35JourneyDataExtract07Dec2016-13Dec2016.csv',\n",
       " 'data/bikes\\\\36JourneyDataExtract14Dec2016-20Dec2016.csv',\n",
       " 'data/bikes\\\\37JourneyDataExtract21Dec2016-27Dec2016.csv',\n",
       " 'data/bikes\\\\38JourneyDataExtract28Dec2016-03Jan2017.csv',\n",
       " 'data/bikes\\\\39JourneyDataExtract04Jan2017-10Jan2017.csv',\n",
       " 'data/bikes\\\\3a.JourneyDataExtract01Mar15-15Mar15.csv',\n",
       " 'data/bikes\\\\3b.JourneyDataExtract16Mar15-31Mar15.csv',\n",
       " 'data/bikes\\\\4. Journey Data Extract 01Apr14-26Apr14.csv',\n",
       " 'data/bikes\\\\4. Journey Data Extract 03Mar-31Mar13.csv',\n",
       " 'data/bikes\\\\4. Journey Data Extract_1Apr-28Apr12.csv',\n",
       " 'data/bikes\\\\40JourneyDataExtract11Jan2017-17Jan2017.csv',\n",
       " 'data/bikes\\\\41JourneyDataExtract18Jan2017-24Jan2017.csv',\n",
       " 'data/bikes\\\\42JourneyDataExtract25Jan2017-31Jan2017.csv',\n",
       " 'data/bikes\\\\43JourneyDataExtract01Feb2017-07Feb2017.csv',\n",
       " 'data/bikes\\\\44JourneyDataExtract08Feb2017-14Feb2017.csv',\n",
       " 'data/bikes\\\\45JourneyDataExtract15Feb2017-21Feb2017.csv',\n",
       " 'data/bikes\\\\46JourneyDataExtract22Feb2017-28Feb2017.csv',\n",
       " 'data/bikes\\\\47JourneyDataExtract01Mar2017-07Mar2017.csv',\n",
       " 'data/bikes\\\\48JourneyDataExtract08Mar2017-14Mar2017.csv',\n",
       " 'data/bikes\\\\49JourneyDataExtract15Mar2017-21Mar2017.csv',\n",
       " 'data/bikes\\\\4a.JourneyDataExtract01Apr15-16Apr15.csv',\n",
       " 'data/bikes\\\\4b.JourneyDataExtract 17Apr15-02May15.csv',\n",
       " 'data/bikes\\\\5. Journey Data Extract 01Apr-27Apr13.csv',\n",
       " 'data/bikes\\\\5. Journey Data Extract 27Apr14-24May14.csv',\n",
       " 'data/bikes\\\\5. Journey Data Extract_29Apr-26May12.csv',\n",
       " 'data/bikes\\\\50 Journey Data Extract 22Mar2017-28Mar2017.csv',\n",
       " 'data/bikes\\\\51 Journey Data Extract 29Mar2017-04Apr2017.csv',\n",
       " 'data/bikes\\\\52 Journey Data Extract 05Apr2017-11Apr2017.csv',\n",
       " 'data/bikes\\\\53JourneyDataExtract12Apr2017-18Apr2017.csv',\n",
       " 'data/bikes\\\\54JourneyDataExtract19Apr2017-25Apr2017.csv',\n",
       " 'data/bikes\\\\55JourneyData Extract26Apr2017-02May2017.csv',\n",
       " 'data/bikes\\\\56JourneyDataExtract 03May2017-09May2017.csv',\n",
       " 'data/bikes\\\\57JourneyDataExtract10May2017-16May2017.csv',\n",
       " 'data/bikes\\\\5a.JourneyDataExtract03May15-16May15.csv',\n",
       " 'data/bikes\\\\5b.JourneyDataExtract17May15-30May15.csv',\n",
       " 'data/bikes\\\\6. Journey Data Extract 25May14-21Jun14.csv',\n",
       " 'data/bikes\\\\6. Journey Data Extract 28Apr-25May13.csv',\n",
       " 'data/bikes\\\\6. Journey Data Extract_27May-23Jun12.csv',\n",
       " 'data/bikes\\\\6aJourneyDataExtract31May15-12Jun15.csv',\n",
       " 'data/bikes\\\\6bJourneyDataExtract13Jun15-27Jun15.csv',\n",
       " 'data/bikes\\\\7. Journey Data Extract 22Jun14-19Jul14.csv',\n",
       " 'data/bikes\\\\7. Journey Data Extract 26May-22Jun13.csv',\n",
       " 'data/bikes\\\\7. Journey Data Extract_24Jun-21Jul12.csv',\n",
       " 'data/bikes\\\\7a.JourneyDataExtract28Jun15-11Jul15.csv',\n",
       " 'data/bikes\\\\7b.JourneyDataExtract12Jul15-25Jul15.csv',\n",
       " 'data/bikes\\\\8. Journey Data Extract 22Jul-18Aug12.csv',\n",
       " 'data/bikes\\\\8. Journey Data Extract 23Jun-20Jul13.csv',\n",
       " 'data/bikes\\\\8a Journey Data Extract 20Jul14-31Jul14.csv',\n",
       " 'data/bikes\\\\8aJourneyDataExtract26Jul15-07Aug15.csv',\n",
       " 'data/bikes\\\\8b Journey Data Extract 01Aug14-16Aug14.csv',\n",
       " 'data/bikes\\\\8bJourneyData Extract 08Aug15-22Aug15.csv',\n",
       " 'data/bikes\\\\9. Journey Data Extract 19Aug-20 Aug12.csv',\n",
       " 'data/bikes\\\\9. Journey Data Extract 21Jul-17Aug13.csv',\n",
       " 'data/bikes\\\\9a Journey Data Extract 17Aug14-31Aug14.csv',\n",
       " 'data/bikes\\\\9a-Journey-Data-Extract-23Aug15-05Sep15.csv',\n",
       " 'data/bikes\\\\9b Journey Data Extract 01Sep14-13Sep14.csv',\n",
       " 'data/bikes\\\\9b-Journey-Data-Extract-06Sep15-19Sep15.csv']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob \n",
    "\n",
    "# using glob to list all the csv file in the bikefolder filepath\n",
    "all_csv = glob(bikefolder+str('/*.csv'))\n",
    "all_csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2019 data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of csv files that contain '2019' and '2022' respectively\n",
    "csv_2019 = [item for item in all_csv if '2019' in item]\n",
    "csv_2022 = [item for item in all_csv if '2022' in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/bikes\\\\142JourneyDataExtract26Dec2018-01Jan2019.csv',\n",
       " 'data/bikes\\\\143JourneyDataExtract02Jan2019-08Jan2019.csv',\n",
       " 'data/bikes\\\\144JourneyDataExtract09Jan2019-15Jan2019.csv',\n",
       " 'data/bikes\\\\145JourneyDataExtract16Jan2019-22Jan2019.csv',\n",
       " 'data/bikes\\\\146JourneyDataExtract23Jan2019-29Jan2019.csv',\n",
       " 'data/bikes\\\\147JourneyDataExtract30Jan2019-05Feb2019.csv',\n",
       " 'data/bikes\\\\148JourneyDataExtract06Feb2019-12Feb2019.csv',\n",
       " 'data/bikes\\\\149JourneyDataExtract13Feb2019-19Feb2019.csv',\n",
       " 'data/bikes\\\\150JourneyDataExtract20Feb2019-26Feb2019.csv',\n",
       " 'data/bikes\\\\151JourneyDataExtract27Feb2019-05Mar2019.csv',\n",
       " 'data/bikes\\\\152JourneyDataExtract06Mar2019-12Mar2019.csv',\n",
       " 'data/bikes\\\\153JourneyDataExtract13Mar2019-19Mar2019.csv',\n",
       " 'data/bikes\\\\154JourneyDataExtract20Mar2019-26Mar2019.csv',\n",
       " 'data/bikes\\\\155JourneyDataExtract27Mar2019-02Apr2019.csv',\n",
       " 'data/bikes\\\\156JourneyDataExtract03Apr2019-09Apr2019.csv',\n",
       " 'data/bikes\\\\157JourneyDataExtract10Apr2019-16Apr2019.csv',\n",
       " 'data/bikes\\\\158JourneyDataExtract17Apr2019-23Apr2019.csv',\n",
       " 'data/bikes\\\\159JourneyDataExtract24Apr2019-30Apr2019.csv',\n",
       " 'data/bikes\\\\160JourneyDataExtract01May2019-07May2019.csv',\n",
       " 'data/bikes\\\\161JourneyDataExtract08May2019-14May2019.csv',\n",
       " 'data/bikes\\\\162JourneyDataExtract15May2019-21May2019.csv',\n",
       " 'data/bikes\\\\163JourneyDataExtract22May2019-28May2019.csv',\n",
       " 'data/bikes\\\\164JourneyDataExtract29May2019-04Jun2019.csv',\n",
       " 'data/bikes\\\\165JourneyDataExtract05Jun2019-11Jun2019.csv',\n",
       " 'data/bikes\\\\166JourneyDataExtract12Jun2019-18Jun2019.csv',\n",
       " 'data/bikes\\\\167JourneyDataExtract19Jun2019-25Jun2019.csv',\n",
       " 'data/bikes\\\\168JourneyDataExtract26Jun2019-02Jul2019.csv',\n",
       " 'data/bikes\\\\169JourneyDataExtract03Jul2019-09Jul2019.csv',\n",
       " 'data/bikes\\\\170JourneyDataExtract10Jul2019-16Jul2019.csv',\n",
       " 'data/bikes\\\\171JourneyDataExtract17Jul2019-23Jul2019.csv',\n",
       " 'data/bikes\\\\172JourneyDataExtract24Jul2019-30Jul2019.csv',\n",
       " 'data/bikes\\\\173JourneyDataExtract31Jul2019-06Aug2019.csv',\n",
       " 'data/bikes\\\\174JourneyDataExtract07Aug2019-13Aug2019.csv',\n",
       " 'data/bikes\\\\175JourneyDataExtract14Aug2019-20Aug2019.csv',\n",
       " 'data/bikes\\\\176JourneyDataExtract21Aug2019-27Aug2019.csv',\n",
       " 'data/bikes\\\\177JourneyDataExtract28Aug2019-03Sep2019.csv',\n",
       " 'data/bikes\\\\178JourneyDataExtract04Sep2019-10Sep2019.csv',\n",
       " 'data/bikes\\\\179JourneyDataExtract11Sep2019-17Sep2019.csv',\n",
       " 'data/bikes\\\\180JourneyDataExtract18Sep2019-24Sep2019.csv',\n",
       " 'data/bikes\\\\181JourneyDataExtract25Sep2019-01Oct2019.csv',\n",
       " 'data/bikes\\\\182JourneyDataExtract02Oct2019-08Oct2019.csv',\n",
       " 'data/bikes\\\\183JourneyDataExtract09Oct2019-15Oct2019.csv',\n",
       " 'data/bikes\\\\184JourneyDataExtract16Oct2019-22Oct2019.csv',\n",
       " 'data/bikes\\\\185JourneyDataExtract23Oct2019-29Oct2019.csv',\n",
       " 'data/bikes\\\\186JourneyDataExtract30Oct2019-05Nov2019.csv',\n",
       " 'data/bikes\\\\187JourneyDataExtract06Nov2019-12Nov2019.csv',\n",
       " 'data/bikes\\\\188JourneyDataExtract13Nov2019-19Nov2019.csv',\n",
       " 'data/bikes\\\\189JourneyDataExtract20Nov2019-26Nov2019.csv',\n",
       " 'data/bikes\\\\190JourneyDataExtract27Nov2019-03Dec2019.csv',\n",
       " 'data/bikes\\\\191JourneyDataExtract04Dec2019-10Dec2019.csv',\n",
       " 'data/bikes\\\\192JourneyDataExtract11Dec2019-17Dec2019.csv',\n",
       " 'data/bikes\\\\193JourneyDataExtract18Dec2019-24Dec2019.csv',\n",
       " 'data/bikes\\\\194JourneyDataExtract25Dec2019-31Dec2019.csv']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using list comprehension that reads each csv file from the list and gnerators a sequence of dataframes\n",
    "dfs = (pd.read_csv(csv) for csv in csv_2019)\n",
    "\n",
    "# concatenate csvs them into a single DataFrame using pd.concat()\n",
    "# ignore_index=True parameter resets the index of the resulting DataFrame, so that it is a continuous sequence of integers.\n",
    "data_2019 = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10388411, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rental Id</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Bike Id</th>\n",
       "      <th>End Date</th>\n",
       "      <th>EndStation Id</th>\n",
       "      <th>EndStation Name</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>StartStation Id</th>\n",
       "      <th>StartStation Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83252102</td>\n",
       "      <td>720</td>\n",
       "      <td>2077</td>\n",
       "      <td>31/12/2018 19:05</td>\n",
       "      <td>272</td>\n",
       "      <td>Baylis Road, Waterloo</td>\n",
       "      <td>31/12/2018 18:53</td>\n",
       "      <td>94</td>\n",
       "      <td>Bricklayers Arms, Borough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83195883</td>\n",
       "      <td>120</td>\n",
       "      <td>10781</td>\n",
       "      <td>27/12/2018 19:47</td>\n",
       "      <td>93</td>\n",
       "      <td>Cloudesley Road, Angel</td>\n",
       "      <td>27/12/2018 19:45</td>\n",
       "      <td>339</td>\n",
       "      <td>Risinghill Street, Angel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83196070</td>\n",
       "      <td>120</td>\n",
       "      <td>2977</td>\n",
       "      <td>27/12/2018 20:11</td>\n",
       "      <td>339</td>\n",
       "      <td>Risinghill Street, Angel</td>\n",
       "      <td>27/12/2018 20:09</td>\n",
       "      <td>234</td>\n",
       "      <td>Liverpool Road (N1 Centre), Angel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83197932</td>\n",
       "      <td>660</td>\n",
       "      <td>10802</td>\n",
       "      <td>28/12/2018 07:35</td>\n",
       "      <td>282</td>\n",
       "      <td>Royal London Hospital, Whitechapel</td>\n",
       "      <td>28/12/2018 07:24</td>\n",
       "      <td>698</td>\n",
       "      <td>Shoreditch Court, Haggerston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83176351</td>\n",
       "      <td>1380</td>\n",
       "      <td>15749</td>\n",
       "      <td>26/12/2018 11:55</td>\n",
       "      <td>785</td>\n",
       "      <td>Aquatic Centre, Queen Elizabeth Olympic Park</td>\n",
       "      <td>26/12/2018 11:32</td>\n",
       "      <td>783</td>\n",
       "      <td>Monier Road, Hackney Wick</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rental Id  Duration  Bike Id          End Date  EndStation Id  \\\n",
       "0   83252102       720     2077  31/12/2018 19:05            272   \n",
       "1   83195883       120    10781  27/12/2018 19:47             93   \n",
       "2   83196070       120     2977  27/12/2018 20:11            339   \n",
       "3   83197932       660    10802  28/12/2018 07:35            282   \n",
       "4   83176351      1380    15749  26/12/2018 11:55            785   \n",
       "\n",
       "                                EndStation Name        Start Date  \\\n",
       "0                         Baylis Road, Waterloo  31/12/2018 18:53   \n",
       "1                        Cloudesley Road, Angel  27/12/2018 19:45   \n",
       "2                      Risinghill Street, Angel  27/12/2018 20:09   \n",
       "3            Royal London Hospital, Whitechapel  28/12/2018 07:24   \n",
       "4  Aquatic Centre, Queen Elizabeth Olympic Park  26/12/2018 11:32   \n",
       "\n",
       "   StartStation Id                  StartStation Name  \n",
       "0               94          Bricklayers Arms, Borough  \n",
       "1              339           Risinghill Street, Angel  \n",
       "2              234  Liverpool Road (N1 Centre), Angel  \n",
       "3              698       Shoreditch Court, Haggerston  \n",
       "4              783          Monier Road, Hackney Wick  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data_2019.shape)\n",
    "data_2019.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rental Id</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Bike Id</th>\n",
       "      <th>End Date</th>\n",
       "      <th>EndStation Id</th>\n",
       "      <th>EndStation Name</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>StartStation Id</th>\n",
       "      <th>StartStation Name</th>\n",
       "      <th>Start Date Time</th>\n",
       "      <th>Hours</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83252102</td>\n",
       "      <td>720</td>\n",
       "      <td>2077</td>\n",
       "      <td>31/12/2018 19:05</td>\n",
       "      <td>272</td>\n",
       "      <td>Baylis Road, Waterloo</td>\n",
       "      <td>31/12/2018 18:53</td>\n",
       "      <td>94</td>\n",
       "      <td>Bricklayers Arms, Borough</td>\n",
       "      <td>2018-12-31 18:53:00</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83195883</td>\n",
       "      <td>120</td>\n",
       "      <td>10781</td>\n",
       "      <td>27/12/2018 19:47</td>\n",
       "      <td>93</td>\n",
       "      <td>Cloudesley Road, Angel</td>\n",
       "      <td>27/12/2018 19:45</td>\n",
       "      <td>339</td>\n",
       "      <td>Risinghill Street, Angel</td>\n",
       "      <td>2018-12-27 19:45:00</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83196070</td>\n",
       "      <td>120</td>\n",
       "      <td>2977</td>\n",
       "      <td>27/12/2018 20:11</td>\n",
       "      <td>339</td>\n",
       "      <td>Risinghill Street, Angel</td>\n",
       "      <td>27/12/2018 20:09</td>\n",
       "      <td>234</td>\n",
       "      <td>Liverpool Road (N1 Centre), Angel</td>\n",
       "      <td>2018-12-27 20:09:00</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83197932</td>\n",
       "      <td>660</td>\n",
       "      <td>10802</td>\n",
       "      <td>28/12/2018 07:35</td>\n",
       "      <td>282</td>\n",
       "      <td>Royal London Hospital, Whitechapel</td>\n",
       "      <td>28/12/2018 07:24</td>\n",
       "      <td>698</td>\n",
       "      <td>Shoreditch Court, Haggerston</td>\n",
       "      <td>2018-12-28 07:24:00</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83176351</td>\n",
       "      <td>1380</td>\n",
       "      <td>15749</td>\n",
       "      <td>26/12/2018 11:55</td>\n",
       "      <td>785</td>\n",
       "      <td>Aquatic Centre, Queen Elizabeth Olympic Park</td>\n",
       "      <td>26/12/2018 11:32</td>\n",
       "      <td>783</td>\n",
       "      <td>Monier Road, Hackney Wick</td>\n",
       "      <td>2018-12-26 11:32:00</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rental Id  Duration  Bike Id          End Date  EndStation Id  \\\n",
       "0   83252102       720     2077  31/12/2018 19:05            272   \n",
       "1   83195883       120    10781  27/12/2018 19:47             93   \n",
       "2   83196070       120     2977  27/12/2018 20:11            339   \n",
       "3   83197932       660    10802  28/12/2018 07:35            282   \n",
       "4   83176351      1380    15749  26/12/2018 11:55            785   \n",
       "\n",
       "                                EndStation Name        Start Date  \\\n",
       "0                         Baylis Road, Waterloo  31/12/2018 18:53   \n",
       "1                        Cloudesley Road, Angel  27/12/2018 19:45   \n",
       "2                      Risinghill Street, Angel  27/12/2018 20:09   \n",
       "3            Royal London Hospital, Whitechapel  28/12/2018 07:24   \n",
       "4  Aquatic Centre, Queen Elizabeth Olympic Park  26/12/2018 11:32   \n",
       "\n",
       "   StartStation Id                  StartStation Name     Start Date Time  \\\n",
       "0               94          Bricklayers Arms, Borough 2018-12-31 18:53:00   \n",
       "1              339           Risinghill Street, Angel 2018-12-27 19:45:00   \n",
       "2              234  Liverpool Road (N1 Centre), Angel 2018-12-27 20:09:00   \n",
       "3              698       Shoreditch Court, Haggerston 2018-12-28 07:24:00   \n",
       "4              783          Monier Road, Hackney Wick 2018-12-26 11:32:00   \n",
       "\n",
       "   Hours  Minute  Day  \n",
       "0     18      18    0  \n",
       "1     19      19    3  \n",
       "2     20      20    3  \n",
       "3      7       7    4  \n",
       "4     11      11    2  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2019\n",
    "\n",
    "## Add some extra variables to the dataset for use later in filtering\n",
    "\n",
    "import datetime\n",
    "\n",
    "## Feeding a specififed date format speeds up the pd.to_datetime function immeasurably, especially over large datasets\n",
    "## e.g. http://stackoverflow.com/questions/32034689/why-is-pandas-to-datetime-slow-for-non-standard-time-format-such-as-2014-12-31\n",
    "\n",
    "format = \"%d/%m/%Y %H:%M\"\n",
    "\n",
    "## Some routes had dates with a seconds component, whereas some didn't - the below code cuts these seconds off\n",
    "data_2019['Start Date']= data_2019['Start Date'].str[:16]\n",
    "\n",
    "data_2019['Start Date Time']= pd.to_datetime(data_2019['Start Date'], format=format)\n",
    "\n",
    "data_2019['Hours']= pd.to_datetime(data_2019['Start Date'], format=format).dt.hour\n",
    "\n",
    "data_2019['Minute']= pd.to_datetime(data_2019['Start Date'], format=format).dt.hour\n",
    "\n",
    "data_2019['Day']= pd.to_datetime(data_2019['Start Date'], format=format).dt.weekday\n",
    "\n",
    "data_2019.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10310063, 13)\n"
     ]
    }
   ],
   "source": [
    "# 2019 filtering data - remove any rows that aren't from 2019\n",
    "# remember the first csv contained data from 2018... 26Dec2018-01Jan2019.csv\n",
    "bike_data_2019 = data_2019[data_2019['Start Date Time'].dt.year == 2019]\n",
    "print(bike_data_2019.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2022 data prep"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In September 2022 the column names change slightly and additional clumns have been added\n",
    "- for example the 'Bike model' column has been added (classic or PBSC_EBIKE)\n",
    "\n",
    "Cycle Hire Data - data format change & new data https://techforum.tfl.gov.uk/t/cycle-hire-data-data-format-change-new-data/2520"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the 2022 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/bikes\\\\298JourneyDataExtract29Dec2021-04Jan2022.csv',\n",
       " 'data/bikes\\\\299JourneyDataExtract05Jan2022-11Jan2022.csv',\n",
       " 'data/bikes\\\\300JourneyDataExtract12Jan2022-18Jan2022.csv',\n",
       " 'data/bikes\\\\301JourneyDataExtract19Jan2022-25Jan2022.csv',\n",
       " 'data/bikes\\\\302JourneyDataExtract26Jan2022-01Feb2022.csv',\n",
       " 'data/bikes\\\\303JourneyDataExtract02Feb2022-08Feb2022.csv',\n",
       " 'data/bikes\\\\304JourneyDataExtract09Feb2022-15Feb2022.csv',\n",
       " 'data/bikes\\\\305JourneyDataExtract16Feb2022-22Feb2022.csv',\n",
       " 'data/bikes\\\\306JourneyDataExtract23Feb2022-01Mar2022.csv',\n",
       " 'data/bikes\\\\307JourneyDataExtract02Mar2022-08Mar2022.csv',\n",
       " 'data/bikes\\\\308JourneyDataExtract09Mar2022-15Mar2022.csv',\n",
       " 'data/bikes\\\\309JourneyDataExtract16Mar2022-22Mar2022.csv',\n",
       " 'data/bikes\\\\310JourneyDataExtract23Mar2022-29Mar2022.csv',\n",
       " 'data/bikes\\\\311JourneyDataExtract30Mar2022-05Apr2022.csv',\n",
       " 'data/bikes\\\\312JourneyDataExtract06Apr2022-12Apr2022.csv',\n",
       " 'data/bikes\\\\313JourneyDataExtract13Apr2022-19Apr2022.csv',\n",
       " 'data/bikes\\\\314JourneyDataExtract20Apr2022-26Apr2022.csv',\n",
       " 'data/bikes\\\\315JourneyDataExtract27Apr2022-03May2022.csv',\n",
       " 'data/bikes\\\\316JourneyDataExtract04May2022-10May2022.csv',\n",
       " 'data/bikes\\\\317JourneyDataExtract11May2022-17May2022.csv',\n",
       " 'data/bikes\\\\318JourneyDataExtract18May2022-24May2022.csv',\n",
       " 'data/bikes\\\\319JourneyDataExtract25May2022-31May2022.csv',\n",
       " 'data/bikes\\\\320JourneyDataExtract01Jun2022-07Jun2022.csv',\n",
       " 'data/bikes\\\\321JourneyDataExtract08Jun2022-14Jun2022.csv',\n",
       " 'data/bikes\\\\322JourneyDataExtract15Jun2022-21Jun2022.csv',\n",
       " 'data/bikes\\\\323JourneyDataExtract22Jun2022-28Jun2022.csv',\n",
       " 'data/bikes\\\\324JourneyDataExtract29Jun2022-05Jul2022.csv',\n",
       " 'data/bikes\\\\325JourneyDataExtract06Jul2022-12Jul2022.csv',\n",
       " 'data/bikes\\\\326JourneyDataExtract13Jul2022-19Jul2022.csv',\n",
       " 'data/bikes\\\\327JourneyDataExtract20Jul2022-26Jul2022.csv',\n",
       " 'data/bikes\\\\328JourneyDataExtract27Jul2022-02Aug2022.csv',\n",
       " 'data/bikes\\\\329JourneyDataExtract03Aug2022-09Aug2022.csv',\n",
       " 'data/bikes\\\\330JourneyDataExtract10Aug2022-16Aug2022.csv',\n",
       " 'data/bikes\\\\331JourneyDataExtract17Aug2022-23Aug2022.csv',\n",
       " 'data/bikes\\\\332JourneyDataExtract24Aug2022-30Aug2022.csv',\n",
       " 'data/bikes\\\\333JourneyDataExtract31Aug2022-06Sep2022.csv',\n",
       " 'data/bikes\\\\334JourneyDataExtract07Sep2022-11Sep2022.csv',\n",
       " 'data/bikes\\\\335JourneyDataExtract12Sep2022-18Sep2022.csv',\n",
       " 'data/bikes\\\\336JourneyDataExtract19Sep2022-25Sep2022.csv',\n",
       " 'data/bikes\\\\337JourneyDataExtract26Sep2022-02Oct2022.csv',\n",
       " 'data/bikes\\\\338JourneyDataExtract03Oct2022-09Oct2022.csv',\n",
       " 'data/bikes\\\\339JourneyDataExtract10Oct2022-16Oct2022.csv',\n",
       " 'data/bikes\\\\340JourneyDataExtract17Oct2022-23Oct2022.csv',\n",
       " 'data/bikes\\\\341JourneyDataExtract24Oct2022-30Oct2022.csv',\n",
       " 'data/bikes\\\\342JourneyDataExtract31Oct2022-06Nov2022.csv',\n",
       " 'data/bikes\\\\343JourneyDataExtract07Nov2022-13Nov2022.csv',\n",
       " 'data/bikes\\\\344JourneyDataExtract14Nov2022-20Nov2022.csv',\n",
       " 'data/bikes\\\\345JourneyDataExtract21Nov2022-27Nov2022.csv',\n",
       " 'data/bikes\\\\346JourneyDataExtract28Nov2022-04Dec2022.csv',\n",
       " 'data/bikes\\\\347JourneyDataExtract05Dec2022-11Dec2022.csv',\n",
       " 'data/bikes\\\\348JourneyDataExtract12Dec2022-18Dec2022.csv',\n",
       " 'data/bikes\\\\349JourneyDataExtract19Dec2022-25Dec2022.csv',\n",
       " 'data/bikes\\\\350JourneyDataExtract26Dec2022-01Jan2023.csv']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_2022 = [item for item in all_csv if '2022' in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSVs before September 2022 part 1 data \n",
    "# use slicing to includes all elements of the previous list except for the last 16\n",
    "csv_2022_p1 = csv_2022[:-16]\n",
    "\n",
    "# CSVs From september 12th 2022 \n",
    "# use slicing to create a new list that includes only the last 16 elements\n",
    "csv_2022_p2 = csv_2022[-16:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing the same for the 2022 data\n",
    "# passing errors within the csv files as per https://stackoverflow.com/questions/52105659/pandas-read-csv-unexpected-end-of-data-error\n",
    "dfs_2022_p1 = (pd.read_csv(csv, engine='python', encoding='utf-8', on_bad_lines='skip') for csv in csv_2022_p1)\n",
    "data_2022_p1 = pd.concat(dfs_2022_p1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rental Id                 0\n",
       "Duration                  0\n",
       "Bike Id                   0\n",
       "End Date                  0\n",
       "EndStation Id        312144\n",
       "EndStation Name           0\n",
       "Start Date                0\n",
       "StartStation Id           0\n",
       "StartStation Name         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2022_p1.isnull().sum()\n",
    "# for the part 1 data, there were 312144 records with null station ids  \n",
    "\n",
    "#es_id_null = data_2022_p1.loc[data_2022_p1['EndStation Id'].isnull()] \n",
    "#es_id_null.sort_values(by='Start Date', ascending=False)\n",
    "\n",
    "# filtering the data above reveal the journeys taken between 06/07/2022 00:00 and 12/07/2022 23:56 did not record an end station Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rental Id            8677104\n",
       "Duration             8677104\n",
       "Bike Id              8677104\n",
       "End Date             8677104\n",
       "EndStation Id        8364960\n",
       "EndStation Name      8677104\n",
       "Start Date           8677104\n",
       "StartStation Id      8677104\n",
       "StartStation Name    8677104\n",
       "dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2022_p1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EMoses\\AppData\\Local\\Temp\\ipykernel_19104\\3155316714.py:2: DtypeWarning: Columns (2,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dfs_2022_p2 = (pd.read_csv(csv) for csv in csv_2022_p2)\n"
     ]
    }
   ],
   "source": [
    "# read in data with datetime data type for column 2 and column 5\n",
    "dfs_2022_p2 = (pd.read_csv(csv) for csv in csv_2022_p2)\n",
    "#dfs_2022_p2 = (pd.read_csv(csv, parse_dates={'Start date': 'datetime64', 'End date': 'datetime64'}) for csv in csv_2022_p2)\n",
    "data_2022_p2 = pd.concat(dfs_2022_p2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Number                  0\n",
       "Start date              0\n",
       "Start station number    0\n",
       "Start station           0\n",
       "End date                0\n",
       "End station number      0\n",
       "End station             0\n",
       "Bike number             0\n",
       "Bike model              0\n",
       "Total duration          0\n",
       "Total duration (ms)     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2022_p2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Number                  2555077\n",
       "Start date              2555077\n",
       "Start station number    2555077\n",
       "Start station           2555077\n",
       "End date                2555077\n",
       "End station number      2555077\n",
       "End station             2555077\n",
       "Bike number             2555077\n",
       "Bike model              2555077\n",
       "Total duration          2555077\n",
       "Total duration (ms)     2555077\n",
       "dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2022_p2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing the same for the 2022 data\n",
    "# passing errors within the csv files as per https://stackoverflow.com/questions/52105659/pandas-read-csv-unexpected-end-of-data-error\n",
    "dfs_2022 = (pd.read_csv(csv, engine='python', encoding='utf-8', on_bad_lines='skip') for csv in csv_2022)\n",
    "data_2022 = pd.concat(dfs_2022, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    }
   ],
   "source": [
    "# check the data type of the 'date' column\n",
    "print(data_2022['Start date'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2022\n",
    "\n",
    "# Let's clean this up and get all the data into single columns\n",
    "\n",
    "\n",
    "#creating a copy of the orginal data\n",
    "data_2022_clean = data_2022.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's start by sorting out the date time formatting\n",
    "format = \"%d/%m/%Y %H:%M\"\n",
    "format2 = \"%Y/%m/%d %H:%M\"\n",
    "\n",
    "data_2022_clean['Start Date'] = data_2022_clean['Start Date'].str[:16]\n",
    "data_2022_clean['Start Date Time'] = pd.to_datetime(data_2022_clean['Start Date'], format=format)\n",
    "data_2022_clean['Start Date Time 2']= pd.to_datetime(data_2022_clean['Start date'], format=format2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rental Id</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Bike Id</th>\n",
       "      <th>End Date</th>\n",
       "      <th>EndStation Id</th>\n",
       "      <th>EndStation Name</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>StartStation Id</th>\n",
       "      <th>StartStation Name</th>\n",
       "      <th>Number</th>\n",
       "      <th>...</th>\n",
       "      <th>Start station</th>\n",
       "      <th>End date</th>\n",
       "      <th>End station number</th>\n",
       "      <th>End station</th>\n",
       "      <th>Bike number</th>\n",
       "      <th>Bike model</th>\n",
       "      <th>Total duration</th>\n",
       "      <th>Total duration (ms)</th>\n",
       "      <th>Start Date Time</th>\n",
       "      <th>Start Date Time 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115967515.0</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>15338.0</td>\n",
       "      <td>01/01/2022 23:13</td>\n",
       "      <td>310.0</td>\n",
       "      <td>Black Prince Road, Vauxhall</td>\n",
       "      <td>01/01/2022 22:52</td>\n",
       "      <td>529.0</td>\n",
       "      <td>Manresa Road, Chelsea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-01 22:52:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>116017034.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>19861.0</td>\n",
       "      <td>04/01/2022 19:08</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Brunswick Square, Bloomsbury</td>\n",
       "      <td>04/01/2022 18:56</td>\n",
       "      <td>804.0</td>\n",
       "      <td>Good's Way, King's Cross</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-04 18:56:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115895660.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>19666.0</td>\n",
       "      <td>29/12/2021 16:34</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Calshot Street , King's Cross</td>\n",
       "      <td>29/12/2021 16:28</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Guilford Street , Bloomsbury</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-12-29 16:28:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116016563.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>19861.0</td>\n",
       "      <td>04/01/2022 18:46</td>\n",
       "      <td>804.0</td>\n",
       "      <td>Good's Way, King's Cross</td>\n",
       "      <td>04/01/2022 18:38</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Guilford Street , Bloomsbury</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-04 18:38:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>116014412.0</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>17235.0</td>\n",
       "      <td>04/01/2022 17:45</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Belgrove Street , King's Cross</td>\n",
       "      <td>04/01/2022 17:24</td>\n",
       "      <td>297.0</td>\n",
       "      <td>Geraldine Street, Elephant &amp; Castle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-04 17:24:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11232176</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127641458.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Woodstock Grove, Shepherd's Bush</td>\n",
       "      <td>2022-12-26 01:51</td>\n",
       "      <td>200249</td>\n",
       "      <td>Queen Mary's, Mile End</td>\n",
       "      <td>53664.0</td>\n",
       "      <td>CLASSIC</td>\n",
       "      <td>1h 49m 4s</td>\n",
       "      <td>6544593.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2022-12-26 00:02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11232177</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127641459.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Curlew Street, Shad Thames</td>\n",
       "      <td>2022-12-26 00:34</td>\n",
       "      <td>200147</td>\n",
       "      <td>Salmon Lane, Limehouse</td>\n",
       "      <td>54303.0</td>\n",
       "      <td>CLASSIC</td>\n",
       "      <td>32m 16s</td>\n",
       "      <td>1936877.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2022-12-26 00:02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11232178</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127641453.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Curlew Street, Shad Thames</td>\n",
       "      <td>2022-12-26 00:49</td>\n",
       "      <td>200160</td>\n",
       "      <td>Langdon Park, Poplar</td>\n",
       "      <td>21426.0</td>\n",
       "      <td>CLASSIC</td>\n",
       "      <td>49m 15s</td>\n",
       "      <td>2955280.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2022-12-26 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11232179</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127641454.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Millharbour, Millwall</td>\n",
       "      <td>2022-12-26 01:31</td>\n",
       "      <td>22167</td>\n",
       "      <td>Millharbour, Millwall</td>\n",
       "      <td>54786.0</td>\n",
       "      <td>CLASSIC</td>\n",
       "      <td>1h 30m 27s</td>\n",
       "      <td>5427555.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2022-12-26 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11232180</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127641455.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Curlew Street, Shad Thames</td>\n",
       "      <td>2022-12-26 00:49</td>\n",
       "      <td>200160</td>\n",
       "      <td>Langdon Park, Poplar</td>\n",
       "      <td>30605.0</td>\n",
       "      <td>CLASSIC</td>\n",
       "      <td>48m 22s</td>\n",
       "      <td>2902467.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2022-12-26 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11232181 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Rental Id  Duration  Bike Id          End Date  EndStation Id  \\\n",
       "0         115967515.0    1260.0  15338.0  01/01/2022 23:13          310.0   \n",
       "1         116017034.0     720.0  19861.0  04/01/2022 19:08           11.0   \n",
       "2         115895660.0     360.0  19666.0  29/12/2021 16:34           70.0   \n",
       "3         116016563.0     480.0  19861.0  04/01/2022 18:46          804.0   \n",
       "4         116014412.0    1260.0  17235.0  04/01/2022 17:45           14.0   \n",
       "...               ...       ...      ...               ...            ...   \n",
       "11232176          NaN       NaN      NaN               NaN            NaN   \n",
       "11232177          NaN       NaN      NaN               NaN            NaN   \n",
       "11232178          NaN       NaN      NaN               NaN            NaN   \n",
       "11232179          NaN       NaN      NaN               NaN            NaN   \n",
       "11232180          NaN       NaN      NaN               NaN            NaN   \n",
       "\n",
       "                         EndStation Name        Start Date  StartStation Id  \\\n",
       "0            Black Prince Road, Vauxhall  01/01/2022 22:52            529.0   \n",
       "1           Brunswick Square, Bloomsbury  04/01/2022 18:56            804.0   \n",
       "2          Calshot Street , King's Cross  29/12/2021 16:28             57.0   \n",
       "3               Good's Way, King's Cross  04/01/2022 18:38             57.0   \n",
       "4         Belgrove Street , King's Cross  04/01/2022 17:24            297.0   \n",
       "...                                  ...               ...              ...   \n",
       "11232176                             NaN               NaN              NaN   \n",
       "11232177                             NaN               NaN              NaN   \n",
       "11232178                             NaN               NaN              NaN   \n",
       "11232179                             NaN               NaN              NaN   \n",
       "11232180                             NaN               NaN              NaN   \n",
       "\n",
       "                            StartStation Name       Number  ...  \\\n",
       "0                       Manresa Road, Chelsea          NaN  ...   \n",
       "1                    Good's Way, King's Cross          NaN  ...   \n",
       "2                Guilford Street , Bloomsbury          NaN  ...   \n",
       "3                Guilford Street , Bloomsbury          NaN  ...   \n",
       "4         Geraldine Street, Elephant & Castle          NaN  ...   \n",
       "...                                       ...          ...  ...   \n",
       "11232176                                  NaN  127641458.0  ...   \n",
       "11232177                                  NaN  127641459.0  ...   \n",
       "11232178                                  NaN  127641453.0  ...   \n",
       "11232179                                  NaN  127641454.0  ...   \n",
       "11232180                                  NaN  127641455.0  ...   \n",
       "\n",
       "                             Start station          End date  \\\n",
       "0                                      NaN               NaN   \n",
       "1                                      NaN               NaN   \n",
       "2                                      NaN               NaN   \n",
       "3                                      NaN               NaN   \n",
       "4                                      NaN               NaN   \n",
       "...                                    ...               ...   \n",
       "11232176  Woodstock Grove, Shepherd's Bush  2022-12-26 01:51   \n",
       "11232177        Curlew Street, Shad Thames  2022-12-26 00:34   \n",
       "11232178        Curlew Street, Shad Thames  2022-12-26 00:49   \n",
       "11232179             Millharbour, Millwall  2022-12-26 01:31   \n",
       "11232180        Curlew Street, Shad Thames  2022-12-26 00:49   \n",
       "\n",
       "         End station number             End station Bike number Bike model  \\\n",
       "0                       NaN                     NaN         NaN        NaN   \n",
       "1                       NaN                     NaN         NaN        NaN   \n",
       "2                       NaN                     NaN         NaN        NaN   \n",
       "3                       NaN                     NaN         NaN        NaN   \n",
       "4                       NaN                     NaN         NaN        NaN   \n",
       "...                     ...                     ...         ...        ...   \n",
       "11232176             200249  Queen Mary's, Mile End     53664.0    CLASSIC   \n",
       "11232177             200147  Salmon Lane, Limehouse     54303.0    CLASSIC   \n",
       "11232178             200160    Langdon Park, Poplar     21426.0    CLASSIC   \n",
       "11232179              22167   Millharbour, Millwall     54786.0    CLASSIC   \n",
       "11232180             200160    Langdon Park, Poplar     30605.0    CLASSIC   \n",
       "\n",
       "          Total duration Total duration (ms)     Start Date Time  \\\n",
       "0                    NaN                 NaN 2022-01-01 22:52:00   \n",
       "1                    NaN                 NaN 2022-01-04 18:56:00   \n",
       "2                    NaN                 NaN 2021-12-29 16:28:00   \n",
       "3                    NaN                 NaN 2022-01-04 18:38:00   \n",
       "4                    NaN                 NaN 2022-01-04 17:24:00   \n",
       "...                  ...                 ...                 ...   \n",
       "11232176       1h 49m 4s           6544593.0                 NaT   \n",
       "11232177         32m 16s           1936877.0                 NaT   \n",
       "11232178         49m 15s           2955280.0                 NaT   \n",
       "11232179      1h 30m 27s           5427555.0                 NaT   \n",
       "11232180         48m 22s           2902467.0                 NaT   \n",
       "\n",
       "           Start Date Time 2  \n",
       "0                        NaT  \n",
       "1                        NaT  \n",
       "2                        NaT  \n",
       "3                        NaT  \n",
       "4                        NaT  \n",
       "...                      ...  \n",
       "11232176 2022-12-26 00:02:00  \n",
       "11232177 2022-12-26 00:02:00  \n",
       "11232178 2022-12-26 00:00:00  \n",
       "11232179 2022-12-26 00:00:00  \n",
       "11232180 2022-12-26 00:00:00  \n",
       "\n",
       "[11232181 rows x 22 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2022_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2022_clean.loc[data_2022_clean['Start Date Time'].isnull(), 'Start Date Time'] = data_2022_clean['Start Date Time 2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rental Id               2555077\n",
       "Duration                2555077\n",
       "Bike Id                 2555077\n",
       "End Date                2555077\n",
       "EndStation Id           2867221\n",
       "EndStation Name         2555077\n",
       "Start Date              2555077\n",
       "StartStation Id         2555077\n",
       "StartStation Name       2555077\n",
       "Number                  8677104\n",
       "Start date              8677104\n",
       "Start station number    8677104\n",
       "Start station           8677104\n",
       "End date                8677104\n",
       "End station number      8677104\n",
       "End station             8677104\n",
       "Bike number             8677104\n",
       "Bike model              8677104\n",
       "Total duration          8677104\n",
       "Total duration (ms)     8677104\n",
       "Start Date Time               0\n",
       "Start Date Time 2       8677104\n",
       "dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2022_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfering values from one pandas column to another pandas column only for null rows\n",
    "\n",
    "data_2022_clean.loc[data_2022_clean['Rental Id'].isnull(), 'Rental Id'] = data_2022_clean['Number']\n",
    "# converting from milliseconds to seconds, multipyling by 1000 \n",
    "data_2022_clean.loc[data_2022_clean['Duration'].isnull(), 'Duration'] = data_2022_clean['Total duration (ms)'] / 1000\n",
    "data_2022_clean.loc[data_2022_clean['Bike Id'].isnull(), 'Bike Id'] = data_2022_clean['Bike number']\n",
    "data_2022_clean.loc[data_2022_clean['End Date'].isnull(), 'End Date'] = data_2022_clean['End date']\n",
    "data_2022_clean.loc[data_2022_clean['EndStation Name'].isnull(), 'EndStation Name'] = data_2022_clean['End station']\n",
    "data_2022_clean.loc[data_2022_clean['Start Date'].isnull(), 'Start Date'] = data_2022_clean['Start date']\n",
    "data_2022_clean.loc[data_2022_clean['StartStation Name'].isnull(), 'StartStation Name'] = data_2022_clean['Start station']\n",
    "\n",
    "#data_2022_clean.sort_values(by='Bike model', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rental Id                     0\n",
       "Duration                      0\n",
       "Bike Id                       0\n",
       "End Date                      0\n",
       "EndStation Id           2867221\n",
       "EndStation Name               0\n",
       "Start Date                    0\n",
       "StartStation Id         2555077\n",
       "StartStation Name             0\n",
       "Number                  8677104\n",
       "Start date              8677104\n",
       "Start station number    8677104\n",
       "Start station           8677104\n",
       "End date                8677104\n",
       "End station number      8677104\n",
       "End station             8677104\n",
       "Bike number             8677104\n",
       "Bike model              8677104\n",
       "Total duration          8677104\n",
       "Total duration (ms)     8677104\n",
       "Start Date Time               0\n",
       "Start Date Time 2       8677104\n",
       "Hours                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2022_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the additional columns\n",
    "data_2022_clean['Hours']= data_2022_clean['Start Date Time'].dt.hour\n",
    "data_2022_clean['Day']= data_2022_clean['Start Date Time'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing columsn that are no longer needed\n",
    "data_2022_clean_drop = data_2022_clean.drop(['Number', 'Start date', 'Start station', 'End date', 'End station',\n",
    "                                             'Bike number', 'Total duration', 'Total duration (ms)', 'Start Date Time 2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rental Id</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Bike Id</th>\n",
       "      <th>End Date</th>\n",
       "      <th>EndStation Id</th>\n",
       "      <th>EndStation Name</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>StartStation Id</th>\n",
       "      <th>StartStation Name</th>\n",
       "      <th>Start station number</th>\n",
       "      <th>End station number</th>\n",
       "      <th>Bike model</th>\n",
       "      <th>Start Date Time</th>\n",
       "      <th>Hours</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115967515.0</td>\n",
       "      <td>1260.000</td>\n",
       "      <td>15338.0</td>\n",
       "      <td>01/01/2022 23:13</td>\n",
       "      <td>310.0</td>\n",
       "      <td>Black Prince Road, Vauxhall</td>\n",
       "      <td>01/01/2022 22:52</td>\n",
       "      <td>529.0</td>\n",
       "      <td>Manresa Road, Chelsea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-01 22:52:00</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>116017034.0</td>\n",
       "      <td>720.000</td>\n",
       "      <td>19861.0</td>\n",
       "      <td>04/01/2022 19:08</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Brunswick Square, Bloomsbury</td>\n",
       "      <td>04/01/2022 18:56</td>\n",
       "      <td>804.0</td>\n",
       "      <td>Good's Way, King's Cross</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-04 18:56:00</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115895660.0</td>\n",
       "      <td>360.000</td>\n",
       "      <td>19666.0</td>\n",
       "      <td>29/12/2021 16:34</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Calshot Street , King's Cross</td>\n",
       "      <td>29/12/2021 16:28</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Guilford Street , Bloomsbury</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-12-29 16:28:00</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116016563.0</td>\n",
       "      <td>480.000</td>\n",
       "      <td>19861.0</td>\n",
       "      <td>04/01/2022 18:46</td>\n",
       "      <td>804.0</td>\n",
       "      <td>Good's Way, King's Cross</td>\n",
       "      <td>04/01/2022 18:38</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Guilford Street , Bloomsbury</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-04 18:38:00</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>116014412.0</td>\n",
       "      <td>1260.000</td>\n",
       "      <td>17235.0</td>\n",
       "      <td>04/01/2022 17:45</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Belgrove Street , King's Cross</td>\n",
       "      <td>04/01/2022 17:24</td>\n",
       "      <td>297.0</td>\n",
       "      <td>Geraldine Street, Elephant &amp; Castle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-04 17:24:00</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11232176</th>\n",
       "      <td>127641458.0</td>\n",
       "      <td>6544.593</td>\n",
       "      <td>53664.0</td>\n",
       "      <td>2022-12-26 01:51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queen Mary's, Mile End</td>\n",
       "      <td>2022-12-26 00:02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Woodstock Grove, Shepherd's Bush</td>\n",
       "      <td>200214</td>\n",
       "      <td>200249</td>\n",
       "      <td>CLASSIC</td>\n",
       "      <td>2022-12-26 00:02:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11232177</th>\n",
       "      <td>127641459.0</td>\n",
       "      <td>1936.877</td>\n",
       "      <td>54303.0</td>\n",
       "      <td>2022-12-26 00:34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Salmon Lane, Limehouse</td>\n",
       "      <td>2022-12-26 00:02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Curlew Street, Shad Thames</td>\n",
       "      <td>1213</td>\n",
       "      <td>200147</td>\n",
       "      <td>CLASSIC</td>\n",
       "      <td>2022-12-26 00:02:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11232178</th>\n",
       "      <td>127641453.0</td>\n",
       "      <td>2955.280</td>\n",
       "      <td>21426.0</td>\n",
       "      <td>2022-12-26 00:49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Langdon Park, Poplar</td>\n",
       "      <td>2022-12-26 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Curlew Street, Shad Thames</td>\n",
       "      <td>1213</td>\n",
       "      <td>200160</td>\n",
       "      <td>CLASSIC</td>\n",
       "      <td>2022-12-26 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11232179</th>\n",
       "      <td>127641454.0</td>\n",
       "      <td>5427.555</td>\n",
       "      <td>54786.0</td>\n",
       "      <td>2022-12-26 01:31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Millharbour, Millwall</td>\n",
       "      <td>2022-12-26 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Millharbour, Millwall</td>\n",
       "      <td>22167</td>\n",
       "      <td>22167</td>\n",
       "      <td>CLASSIC</td>\n",
       "      <td>2022-12-26 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11232180</th>\n",
       "      <td>127641455.0</td>\n",
       "      <td>2902.467</td>\n",
       "      <td>30605.0</td>\n",
       "      <td>2022-12-26 00:49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Langdon Park, Poplar</td>\n",
       "      <td>2022-12-26 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Curlew Street, Shad Thames</td>\n",
       "      <td>1213</td>\n",
       "      <td>200160</td>\n",
       "      <td>CLASSIC</td>\n",
       "      <td>2022-12-26 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11232181 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Rental Id  Duration  Bike Id          End Date  EndStation Id  \\\n",
       "0         115967515.0  1260.000  15338.0  01/01/2022 23:13          310.0   \n",
       "1         116017034.0   720.000  19861.0  04/01/2022 19:08           11.0   \n",
       "2         115895660.0   360.000  19666.0  29/12/2021 16:34           70.0   \n",
       "3         116016563.0   480.000  19861.0  04/01/2022 18:46          804.0   \n",
       "4         116014412.0  1260.000  17235.0  04/01/2022 17:45           14.0   \n",
       "...               ...       ...      ...               ...            ...   \n",
       "11232176  127641458.0  6544.593  53664.0  2022-12-26 01:51            NaN   \n",
       "11232177  127641459.0  1936.877  54303.0  2022-12-26 00:34            NaN   \n",
       "11232178  127641453.0  2955.280  21426.0  2022-12-26 00:49            NaN   \n",
       "11232179  127641454.0  5427.555  54786.0  2022-12-26 01:31            NaN   \n",
       "11232180  127641455.0  2902.467  30605.0  2022-12-26 00:49            NaN   \n",
       "\n",
       "                         EndStation Name        Start Date  StartStation Id  \\\n",
       "0            Black Prince Road, Vauxhall  01/01/2022 22:52            529.0   \n",
       "1           Brunswick Square, Bloomsbury  04/01/2022 18:56            804.0   \n",
       "2          Calshot Street , King's Cross  29/12/2021 16:28             57.0   \n",
       "3               Good's Way, King's Cross  04/01/2022 18:38             57.0   \n",
       "4         Belgrove Street , King's Cross  04/01/2022 17:24            297.0   \n",
       "...                                  ...               ...              ...   \n",
       "11232176          Queen Mary's, Mile End  2022-12-26 00:02              NaN   \n",
       "11232177          Salmon Lane, Limehouse  2022-12-26 00:02              NaN   \n",
       "11232178            Langdon Park, Poplar  2022-12-26 00:00              NaN   \n",
       "11232179           Millharbour, Millwall  2022-12-26 00:00              NaN   \n",
       "11232180            Langdon Park, Poplar  2022-12-26 00:00              NaN   \n",
       "\n",
       "                            StartStation Name Start station number  \\\n",
       "0                       Manresa Road, Chelsea                  NaN   \n",
       "1                    Good's Way, King's Cross                  NaN   \n",
       "2                Guilford Street , Bloomsbury                  NaN   \n",
       "3                Guilford Street , Bloomsbury                  NaN   \n",
       "4         Geraldine Street, Elephant & Castle                  NaN   \n",
       "...                                       ...                  ...   \n",
       "11232176     Woodstock Grove, Shepherd's Bush               200214   \n",
       "11232177           Curlew Street, Shad Thames                 1213   \n",
       "11232178           Curlew Street, Shad Thames                 1213   \n",
       "11232179                Millharbour, Millwall                22167   \n",
       "11232180           Curlew Street, Shad Thames                 1213   \n",
       "\n",
       "         End station number Bike model     Start Date Time  Hours  Day  \n",
       "0                       NaN        NaN 2022-01-01 22:52:00     22    5  \n",
       "1                       NaN        NaN 2022-01-04 18:56:00     18    1  \n",
       "2                       NaN        NaN 2021-12-29 16:28:00     16    2  \n",
       "3                       NaN        NaN 2022-01-04 18:38:00     18    1  \n",
       "4                       NaN        NaN 2022-01-04 17:24:00     17    1  \n",
       "...                     ...        ...                 ...    ...  ...  \n",
       "11232176             200249    CLASSIC 2022-12-26 00:02:00      0    0  \n",
       "11232177             200147    CLASSIC 2022-12-26 00:02:00      0    0  \n",
       "11232178             200160    CLASSIC 2022-12-26 00:00:00      0    0  \n",
       "11232179              22167    CLASSIC 2022-12-26 00:00:00      0    0  \n",
       "11232180             200160    CLASSIC 2022-12-26 00:00:00      0    0  \n",
       "\n",
       "[11232181 rows x 15 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2022_clean_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rental Id                     0\n",
       "Duration                      0\n",
       "Bike Id                       0\n",
       "End Date                      0\n",
       "EndStation Id           2867221\n",
       "EndStation Name               0\n",
       "Start Date                    0\n",
       "StartStation Id         2555077\n",
       "StartStation Name             0\n",
       "Start station number    8677104\n",
       "End station number      8677104\n",
       "Bike model              8677104\n",
       "Start Date Time               0\n",
       "Hours                         0\n",
       "Day                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2022_clean_drop.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rental Id</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Bike Id</th>\n",
       "      <th>End Date</th>\n",
       "      <th>EndStation Id</th>\n",
       "      <th>EndStation Name</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>StartStation Id</th>\n",
       "      <th>StartStation Name</th>\n",
       "      <th>SS Terminal Name</th>\n",
       "      <th>ES Terminal Name</th>\n",
       "      <th>Bike model</th>\n",
       "      <th>Start Date Time</th>\n",
       "      <th>Hours</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115967515.0</td>\n",
       "      <td>1260.000</td>\n",
       "      <td>15338.0</td>\n",
       "      <td>01/01/2022 23:13</td>\n",
       "      <td>310.0</td>\n",
       "      <td>Black Prince Road, Vauxhall</td>\n",
       "      <td>01/01/2022 22:52</td>\n",
       "      <td>529.0</td>\n",
       "      <td>Manresa Road, Chelsea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-01 22:52:00</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>116017034.0</td>\n",
       "      <td>720.000</td>\n",
       "      <td>19861.0</td>\n",
       "      <td>04/01/2022 19:08</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Brunswick Square, Bloomsbury</td>\n",
       "      <td>04/01/2022 18:56</td>\n",
       "      <td>804.0</td>\n",
       "      <td>Good's Way, King's Cross</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-04 18:56:00</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115895660.0</td>\n",
       "      <td>360.000</td>\n",
       "      <td>19666.0</td>\n",
       "      <td>29/12/2021 16:34</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Calshot Street , King's Cross</td>\n",
       "      <td>29/12/2021 16:28</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Guilford Street , Bloomsbury</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-12-29 16:28:00</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116016563.0</td>\n",
       "      <td>480.000</td>\n",
       "      <td>19861.0</td>\n",
       "      <td>04/01/2022 18:46</td>\n",
       "      <td>804.0</td>\n",
       "      <td>Good's Way, King's Cross</td>\n",
       "      <td>04/01/2022 18:38</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Guilford Street , Bloomsbury</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-04 18:38:00</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>116014412.0</td>\n",
       "      <td>1260.000</td>\n",
       "      <td>17235.0</td>\n",
       "      <td>04/01/2022 17:45</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Belgrove Street , King's Cross</td>\n",
       "      <td>04/01/2022 17:24</td>\n",
       "      <td>297.0</td>\n",
       "      <td>Geraldine Street, Elephant &amp; Castle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-04 17:24:00</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11232176</th>\n",
       "      <td>127641458.0</td>\n",
       "      <td>6544.593</td>\n",
       "      <td>53664.0</td>\n",
       "      <td>2022-12-26 01:51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queen Mary's, Mile End</td>\n",
       "      <td>2022-12-26 00:02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Woodstock Grove, Shepherd's Bush</td>\n",
       "      <td>200214</td>\n",
       "      <td>200249</td>\n",
       "      <td>CLASSIC</td>\n",
       "      <td>2022-12-26 00:02:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11232177</th>\n",
       "      <td>127641459.0</td>\n",
       "      <td>1936.877</td>\n",
       "      <td>54303.0</td>\n",
       "      <td>2022-12-26 00:34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Salmon Lane, Limehouse</td>\n",
       "      <td>2022-12-26 00:02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Curlew Street, Shad Thames</td>\n",
       "      <td>1213</td>\n",
       "      <td>200147</td>\n",
       "      <td>CLASSIC</td>\n",
       "      <td>2022-12-26 00:02:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11232178</th>\n",
       "      <td>127641453.0</td>\n",
       "      <td>2955.280</td>\n",
       "      <td>21426.0</td>\n",
       "      <td>2022-12-26 00:49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Langdon Park, Poplar</td>\n",
       "      <td>2022-12-26 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Curlew Street, Shad Thames</td>\n",
       "      <td>1213</td>\n",
       "      <td>200160</td>\n",
       "      <td>CLASSIC</td>\n",
       "      <td>2022-12-26 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11232179</th>\n",
       "      <td>127641454.0</td>\n",
       "      <td>5427.555</td>\n",
       "      <td>54786.0</td>\n",
       "      <td>2022-12-26 01:31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Millharbour, Millwall</td>\n",
       "      <td>2022-12-26 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Millharbour, Millwall</td>\n",
       "      <td>22167</td>\n",
       "      <td>22167</td>\n",
       "      <td>CLASSIC</td>\n",
       "      <td>2022-12-26 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11232180</th>\n",
       "      <td>127641455.0</td>\n",
       "      <td>2902.467</td>\n",
       "      <td>30605.0</td>\n",
       "      <td>2022-12-26 00:49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Langdon Park, Poplar</td>\n",
       "      <td>2022-12-26 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Curlew Street, Shad Thames</td>\n",
       "      <td>1213</td>\n",
       "      <td>200160</td>\n",
       "      <td>CLASSIC</td>\n",
       "      <td>2022-12-26 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11232181 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Rental Id  Duration  Bike Id          End Date  EndStation Id  \\\n",
       "0         115967515.0  1260.000  15338.0  01/01/2022 23:13          310.0   \n",
       "1         116017034.0   720.000  19861.0  04/01/2022 19:08           11.0   \n",
       "2         115895660.0   360.000  19666.0  29/12/2021 16:34           70.0   \n",
       "3         116016563.0   480.000  19861.0  04/01/2022 18:46          804.0   \n",
       "4         116014412.0  1260.000  17235.0  04/01/2022 17:45           14.0   \n",
       "...               ...       ...      ...               ...            ...   \n",
       "11232176  127641458.0  6544.593  53664.0  2022-12-26 01:51            NaN   \n",
       "11232177  127641459.0  1936.877  54303.0  2022-12-26 00:34            NaN   \n",
       "11232178  127641453.0  2955.280  21426.0  2022-12-26 00:49            NaN   \n",
       "11232179  127641454.0  5427.555  54786.0  2022-12-26 01:31            NaN   \n",
       "11232180  127641455.0  2902.467  30605.0  2022-12-26 00:49            NaN   \n",
       "\n",
       "                         EndStation Name        Start Date  StartStation Id  \\\n",
       "0            Black Prince Road, Vauxhall  01/01/2022 22:52            529.0   \n",
       "1           Brunswick Square, Bloomsbury  04/01/2022 18:56            804.0   \n",
       "2          Calshot Street , King's Cross  29/12/2021 16:28             57.0   \n",
       "3               Good's Way, King's Cross  04/01/2022 18:38             57.0   \n",
       "4         Belgrove Street , King's Cross  04/01/2022 17:24            297.0   \n",
       "...                                  ...               ...              ...   \n",
       "11232176          Queen Mary's, Mile End  2022-12-26 00:02              NaN   \n",
       "11232177          Salmon Lane, Limehouse  2022-12-26 00:02              NaN   \n",
       "11232178            Langdon Park, Poplar  2022-12-26 00:00              NaN   \n",
       "11232179           Millharbour, Millwall  2022-12-26 00:00              NaN   \n",
       "11232180            Langdon Park, Poplar  2022-12-26 00:00              NaN   \n",
       "\n",
       "                            StartStation Name SS Terminal Name  \\\n",
       "0                       Manresa Road, Chelsea              NaN   \n",
       "1                    Good's Way, King's Cross              NaN   \n",
       "2                Guilford Street , Bloomsbury              NaN   \n",
       "3                Guilford Street , Bloomsbury              NaN   \n",
       "4         Geraldine Street, Elephant & Castle              NaN   \n",
       "...                                       ...              ...   \n",
       "11232176     Woodstock Grove, Shepherd's Bush           200214   \n",
       "11232177           Curlew Street, Shad Thames             1213   \n",
       "11232178           Curlew Street, Shad Thames             1213   \n",
       "11232179                Millharbour, Millwall            22167   \n",
       "11232180           Curlew Street, Shad Thames             1213   \n",
       "\n",
       "         ES Terminal Name Bike model     Start Date Time  Hours  Day  \n",
       "0                     NaN        NaN 2022-01-01 22:52:00     22    5  \n",
       "1                     NaN        NaN 2022-01-04 18:56:00     18    1  \n",
       "2                     NaN        NaN 2021-12-29 16:28:00     16    2  \n",
       "3                     NaN        NaN 2022-01-04 18:38:00     18    1  \n",
       "4                     NaN        NaN 2022-01-04 17:24:00     17    1  \n",
       "...                   ...        ...                 ...    ...  ...  \n",
       "11232176           200249    CLASSIC 2022-12-26 00:02:00      0    0  \n",
       "11232177           200147    CLASSIC 2022-12-26 00:02:00      0    0  \n",
       "11232178           200160    CLASSIC 2022-12-26 00:00:00      0    0  \n",
       "11232179            22167    CLASSIC 2022-12-26 00:00:00      0    0  \n",
       "11232180           200160    CLASSIC 2022-12-26 00:00:00      0    0  \n",
       "\n",
       "[11232181 rows x 15 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's rename a couple of columns to make it clearer\n",
    "# we will rename the Start and End station number column \n",
    "# these columns actually terminal to the station 'terminalName' as per https://tfl.gov.uk/tfl/syndication/feeds/cycle-hire/livecyclehireupdates.xml\n",
    "\n",
    "data_2022_clean_drop.rename(columns={'Start station number': 'SS Terminal Name', 'End station number': 'ES Terminal Name'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11166111, 15)\n"
     ]
    }
   ],
   "source": [
    "# 2022 filtering data - remove any rows that aren't from 2022\n",
    "bike_data_2022 = data_2022_clean_drop[data_2022_clean_drop['Start Date Time'].dt.year == 2022]\n",
    "print(bike_data_2022.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the data in an PostgreSQL databse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# psycopg2 library installed to connect to a PostgreSQL database from Python\n",
    "\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connection to postgres database\n",
    "conn = psycopg2.connect(\n",
    "    user=\"postgres\",\n",
    "    password=\"password123\",\n",
    "    host=\"localhost\",\n",
    "    database=\"diss_data\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SQLAlchemy engine: Create a SQLAlchemy engine using the create_engine function, which will be used to write the DataFrame to the database.\n",
    "engine = create_engine('postgresql+psycopg2://postgres:password123@localhost:5432/diss_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the DataFrame to the database: Once you have the connection and engine set up, you can use the to_sql method of the DataFrame to export it to the database.\n",
    "# save the DataFrame to the PostgreSQL database\n",
    "# set the index parameter to False to avoid saving the DataFrame's index as a separate column in the database.\n",
    "bike_data_2019.to_sql('bike_data_2019_tb', engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the DataFrame to the PostgreSQL database\n",
    "bike_data_2022.to_sql('bike_data_2022_tb', engine, if_exists='replace', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "249cc518374e28bf1fa10a0460f1501eab88ca4f883968af225d88dc54cdfb38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
