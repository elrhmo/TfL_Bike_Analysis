{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFL Bike data prep\n",
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploratory data analysis as part of my MSc thesis, \"Using machine learning to predict Transport for London bike sharing habits in the post COVID-19 era\"."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code for downloading the data has been adopted from [Markus Hauru's](https://github.com/mhauru) analysis, 'Predicting Boris Bike usage'.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import requests\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model, svm, neighbors, tree\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from timeit import default_timer as timer\n",
    "from IPython.display import set_matplotlib_formats\n",
    "from urllib.parse import urlparse\n",
    "import openpyxl\n",
    "\n",
    "try:\n",
    "    import xlrd\n",
    "except Exception as e:\n",
    "    msg = (\n",
    "        \"Please install the package xlrd: `pip install --user xlrd`\"\n",
    "        \"It's an optional requirement for pandas, and we'll be needing it.\"\n",
    "    )\n",
    "    print(msg)\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EMoses\\AppData\\Local\\Temp\\ipykernel_27248\\99259732.py:4: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats(\"svg\")\n"
     ]
    }
   ],
   "source": [
    "# For pretty and exportable matplotlib plots.\n",
    "# If you are running this yourself and want interactivity,\n",
    "# try `%matplotlib widget` instead.\n",
    "set_matplotlib_formats(\"svg\")\n",
    "%matplotlib inline\n",
    "# %matplotlib widget\n",
    "# Set a consistent plotting style across the notebook using Seaborn.\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(\"notebook\")\n",
    "# Make pandas cooperate with pyplot\n",
    "pd.plotting.register_matplotlib_converters()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Processing and cleaning the bike data\n",
    "Before getting anywhere with it, we'll need to process the bike data quite a bit. The data comes in CSV files, each of which covers a period of time. Up first, we need to download the data from the TfL website. If you are running this code yourself, here's a script that does that. Be warned though, it's almost seven gigs of data. You can run it repeatedly, and it'll only download data that it doesn't have already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikefolder = \"data/bikes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(datafolder, url, verbosity=0):\n",
    "    \"\"\"Download the data from the given URL into the datafolder, unless it's\n",
    "    already there. Return path to downloaded file.\n",
    "    \"\"\"\n",
    "    datafolder = Path(datafolder)\n",
    "    datafolder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    a = urlparse(url)\n",
    "    filename = Path(os.path.basename(a.path))\n",
    "    filepath = datafolder / filename\n",
    "    # Don't redownload if we already have this file.\n",
    "    if filepath.exists():\n",
    "        if verbosity > 1:\n",
    "            print(\"Already have {}\".format(filename))\n",
    "    else:\n",
    "        if verbosity > 0:\n",
    "            print(\"Downloading {}\".format(filename))\n",
    "        rqst = requests.get(url)\n",
    "        rqst.raise_for_status()\n",
    "        with open(filepath, \"wb\") as f:\n",
    "            f.write(rqst.content)\n",
    "    return filepath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust whether to print progress reports of the downloads.\n",
    "# verbosity=0 is silence, verbosity=1 reports only when actually doing things,\n",
    "# verbosity>1 also reports when there's nothing to do.\n",
    "verbosity = 1\n",
    "\n",
    "# Most files are individual CSV files, listed in bike_data_urls.txt. Download them.\n",
    "urlsfile = \"data/bikes/bike_data_urls.txt\"\n",
    "with open(urlsfile, \"r\") as f:\n",
    "    urls = f.read().splitlines()\n",
    "# There are a few comments in the file, marked by lines starting with #.\n",
    "# Filter them out.\n",
    "urls = [u for u in urls if u[0] != \"#\"]\n",
    "for url in urls:\n",
    "    download_file(bikefolder, url, verbosity)\n",
    "\n",
    "# The early years come in zips. Download and unzip them.\n",
    "zipsfolder = Path(\"data/bikes/bikezips\")\n",
    "bikezipurls = [\n",
    "    \"https://cycling.data.tfl.gov.uk/usage-stats/cyclehireusagestats-2012.zip\",\n",
    "    \"https://cycling.data.tfl.gov.uk/usage-stats/cyclehireusagestats-2013.zip\",\n",
    "    \"https://cycling.data.tfl.gov.uk/usage-stats/cyclehireusagestats-2014.zip\",\n",
    "    \"https://cycling.data.tfl.gov.uk/usage-stats/2015TripDatazip.zip\",\n",
    "    \"https://cycling.data.tfl.gov.uk/usage-stats/2016TripDataZip.zip\",\n",
    "]\n",
    "# A list of CSV files that are already there. Only unzip if some of the files\n",
    "# in the zip aren't present already.\n",
    "current_csvs = sorted(os.listdir(bikefolder))\n",
    "for url in bikezipurls:\n",
    "    zippath = download_file(zipsfolder, url, verbosity)\n",
    "    with zipfile.ZipFile(zippath, \"r\") as z:\n",
    "        namelist = z.namelist()\n",
    "        has_been_extracted = any(name not in current_csvs for name in namelist)\n",
    "        if has_been_extracted:\n",
    "            if verbosity > 0:\n",
    "                print(\"Unzipping {}\".format(zippath))\n",
    "            z.extractall(bikefolder)\n",
    "        else:\n",
    "            if verbosity > 1:\n",
    "                print(\"{} has already been extracted.\".format(zippath))\n",
    "\n",
    "# Finally, there's an odd one out: One week's data comes in as an .xlsx.\n",
    "# Download it and use pandas to convert it to csv.\n",
    "xlsxurl = \"https://cycling.data.tfl.gov.uk/usage-stats/49JourneyDataExtract15Mar2017-21Mar2017.xlsx\"\n",
    "xlsxfile = download_file(bikefolder, xlsxurl)\n",
    "csvfile = xlsxfile.with_suffix(\".csv\")\n",
    "if not csvfile.exists():\n",
    "    if verbosity > 0:\n",
    "        print(\"Converting .xlsx to .csv.\")\n",
    "    pd.read_excel(xlsxfile).to_csv(csvfile, date_format=\"%d/%m/%Y %H:%M:%S\")\n",
    "else:\n",
    "    if verbosity > 1:\n",
    "        print(\"Already have {}\".format(csvfile))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we have now lists on each line of the CSV file a single bike trip, with starting point and time, end point and time, and things like bike ID number. Here's an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rental Id</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Bike Id</th>\n",
       "      <th>End Date</th>\n",
       "      <th>EndStation Id</th>\n",
       "      <th>EndStation Name</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>StartStation Id</th>\n",
       "      <th>StartStation Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62857677</td>\n",
       "      <td>3780.0</td>\n",
       "      <td>7851</td>\n",
       "      <td>06/03/2017 19:20</td>\n",
       "      <td>43.0</td>\n",
       "      <td>Crawford Street, Marylebone</td>\n",
       "      <td>06/03/2017 18:17</td>\n",
       "      <td>811</td>\n",
       "      <td>Westferry Circus, Canary Wharf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62863035</td>\n",
       "      <td>540.0</td>\n",
       "      <td>4089</td>\n",
       "      <td>06/03/2017 22:17</td>\n",
       "      <td>295.0</td>\n",
       "      <td>Swan Street, The Borough</td>\n",
       "      <td>06/03/2017 22:08</td>\n",
       "      <td>272</td>\n",
       "      <td>Baylis Road, Waterloo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62775896</td>\n",
       "      <td>600.0</td>\n",
       "      <td>4895</td>\n",
       "      <td>02/03/2017 21:27</td>\n",
       "      <td>295.0</td>\n",
       "      <td>Swan Street, The Borough</td>\n",
       "      <td>02/03/2017 21:17</td>\n",
       "      <td>197</td>\n",
       "      <td>Stamford Street, South Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62747748</td>\n",
       "      <td>420.0</td>\n",
       "      <td>4347</td>\n",
       "      <td>01/03/2017 21:08</td>\n",
       "      <td>295.0</td>\n",
       "      <td>Swan Street, The Borough</td>\n",
       "      <td>01/03/2017 21:01</td>\n",
       "      <td>803</td>\n",
       "      <td>Southwark Street, Bankside</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62843939</td>\n",
       "      <td>420.0</td>\n",
       "      <td>3192</td>\n",
       "      <td>06/03/2017 09:28</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Bankside Mix, Bankside</td>\n",
       "      <td>06/03/2017 09:21</td>\n",
       "      <td>197</td>\n",
       "      <td>Stamford Street, South Bank</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rental Id  Duration  Bike Id          End Date  EndStation Id  \\\n",
       "0   62857677    3780.0     7851  06/03/2017 19:20           43.0   \n",
       "1   62863035     540.0     4089  06/03/2017 22:17          295.0   \n",
       "2   62775896     600.0     4895  02/03/2017 21:27          295.0   \n",
       "3   62747748     420.0     4347  01/03/2017 21:08          295.0   \n",
       "4   62843939     420.0     3192  06/03/2017 09:28          193.0   \n",
       "\n",
       "               EndStation Name        Start Date  StartStation Id  \\\n",
       "0  Crawford Street, Marylebone  06/03/2017 18:17              811   \n",
       "1     Swan Street, The Borough  06/03/2017 22:08              272   \n",
       "2     Swan Street, The Borough  02/03/2017 21:17              197   \n",
       "3     Swan Street, The Borough  01/03/2017 21:01              803   \n",
       "4       Bankside Mix, Bankside  06/03/2017 09:21              197   \n",
       "\n",
       "                StartStation Name  \n",
       "0  Westferry Circus, Canary Wharf  \n",
       "1           Baylis Road, Waterloo  \n",
       "2     Stamford Street, South Bank  \n",
       "3      Southwark Street, Bankside  \n",
       "4     Stamford Street, South Bank  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_file  = Path(bikefolder) / Path(\"47JourneyDataExtract01Mar2017-07Mar2017.csv\")\n",
    "pd.read_csv(example_file, encoding=\"ISO-8859-2\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/bikes'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikefolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/bikes\\\\01aJourneyDataExtract10Jan16-23Jan16.csv',\n",
       " 'data/bikes\\\\01bJourneyDataExtract24Jan16-06Feb16.csv',\n",
       " 'data/bikes\\\\02aJourneyDataExtract07Feb16-20Feb2016.csv',\n",
       " 'data/bikes\\\\02bJourneyDataExtract21Feb16-05Mar2016.csv',\n",
       " 'data/bikes\\\\03JourneyDataExtract06Mar2016-31Mar2016.csv',\n",
       " 'data/bikes\\\\04JourneyDataExtract01Apr2016-30Apr2016.csv',\n",
       " 'data/bikes\\\\05JourneyDataExtract01May2016-17May2016.csv',\n",
       " 'data/bikes\\\\06JourneyDataExtract18May2016-24May2016.csv',\n",
       " 'data/bikes\\\\07JourneyDataExtract25May2016-31May2016.csv',\n",
       " 'data/bikes\\\\08JourneyDataExtract01Jun2016-07Jun2016.csv',\n",
       " 'data/bikes\\\\09JourneyDataExtract08Jun2016-14Jun2016.csv',\n",
       " 'data/bikes\\\\1. Journey Data Extract 01Jan-05Jan13.csv',\n",
       " 'data/bikes\\\\1. Journey Data Extract 04Jan-31Jan 12.csv',\n",
       " 'data/bikes\\\\1. Journey Data Extract 05Jan14-02Feb14.csv',\n",
       " 'data/bikes\\\\10. Journey Data Extract 18Aug-13Sep13.csv',\n",
       " 'data/bikes\\\\10. Journey Data Extract 21Aug-22 Aug12.csv',\n",
       " 'data/bikes\\\\10a Journey Data Extract 20Sep15-03Oct15.csv',\n",
       " 'data/bikes\\\\10a. Journey Data Extract 14Sep14-27Sep14.csv',\n",
       " 'data/bikes\\\\10b Journey Data Extract 04Oct15-17Oct15.csv',\n",
       " 'data/bikes\\\\10b. Journey Data Extract 28Sep14-11Oct14.csv',\n",
       " 'data/bikes\\\\10JourneyDataExtract15Jun2016-21Jun2016.csv',\n",
       " 'data/bikes\\\\11. Journey Data Extract 14Sep13-12Oct13.csv',\n",
       " 'data/bikes\\\\11. Journey Data Extract 23Aug-25 Aug12.csv',\n",
       " 'data/bikes\\\\11a Journey Data Extract 18Oct15-31Oct15.csv',\n",
       " 'data/bikes\\\\11a. Journey Data Extract 12Oct14-08Nov14.csv',\n",
       " 'data/bikes\\\\11b Journey Data Extract 01Nov15-14Nov15.csv',\n",
       " 'data/bikes\\\\11b. Journey Data Extract 12Oct14-08Nov14.csv',\n",
       " 'data/bikes\\\\11JourneyDataExtract22Jun2016-28Jun2016.csv',\n",
       " 'data/bikes\\\\12. Journey Data Extract 13Oct13-09Nov13.csv',\n",
       " 'data/bikes\\\\12. Journey Data Extract 26Aug-27 Aug12.csv',\n",
       " 'data/bikes\\\\12a Journey Data Extract 15Nov15-27Nov15.csv',\n",
       " 'data/bikes\\\\12a. Journey Data Extract 09Nov14-06Dec14.csv',\n",
       " 'data/bikes\\\\12b Journey Data Extract 28Nov15-12Dec15.csv',\n",
       " 'data/bikes\\\\12b. Journey Data Extract 09Nov14-06Dec14.csv',\n",
       " 'data/bikes\\\\12JourneyDataExtract29Jun2016-05Jul2016.csv',\n",
       " 'data/bikes\\\\13. Journey Data Extract 10Nov13-07Dec13.csv',\n",
       " 'data/bikes\\\\13. Journey Data Extract 28Aug-29 Aug12.csv',\n",
       " 'data/bikes\\\\13a Journey Data Extract 13Dec15-24Dec15.csv',\n",
       " 'data/bikes\\\\13a. Journey Data Extract 07Dec14-21Dec14.csv',\n",
       " 'data/bikes\\\\13b Journey Data Extract 25Dec15-09Jan16.csv',\n",
       " 'data/bikes\\\\13b. Journey Data Extract 22Dec14-03Jan15.csv',\n",
       " 'data/bikes\\\\13JourneyDataExtract06Jul2016-12Jul2016.csv',\n",
       " 'data/bikes\\\\14. Journey Data Extract 08Dec13-04Jan14.csv',\n",
       " 'data/bikes\\\\14. Journey Data Extract 30Aug-31 Aug12.csv',\n",
       " 'data/bikes\\\\142JourneyDataExtract26Dec2018-01Jan2019.csv',\n",
       " 'data/bikes\\\\143JourneyDataExtract02Jan2019-08Jan2019.csv',\n",
       " 'data/bikes\\\\144JourneyDataExtract09Jan2019-15Jan2019.csv',\n",
       " 'data/bikes\\\\145JourneyDataExtract16Jan2019-22Jan2019.csv',\n",
       " 'data/bikes\\\\146JourneyDataExtract23Jan2019-29Jan2019.csv',\n",
       " 'data/bikes\\\\147JourneyDataExtract30Jan2019-05Feb2019.csv',\n",
       " 'data/bikes\\\\148JourneyDataExtract06Feb2019-12Feb2019.csv',\n",
       " 'data/bikes\\\\149JourneyDataExtract13Feb2019-19Feb2019.csv',\n",
       " 'data/bikes\\\\14JourneyDataExtract13Jul2016-19Jul2016.csv',\n",
       " 'data/bikes\\\\15. Journey Data Extract 01Sep-30Sep12.csv',\n",
       " 'data/bikes\\\\150JourneyDataExtract20Feb2019-26Feb2019.csv',\n",
       " 'data/bikes\\\\151JourneyDataExtract27Feb2019-05Mar2019.csv',\n",
       " 'data/bikes\\\\152JourneyDataExtract06Mar2019-12Mar2019.csv',\n",
       " 'data/bikes\\\\153JourneyDataExtract13Mar2019-19Mar2019.csv',\n",
       " 'data/bikes\\\\154JourneyDataExtract20Mar2019-26Mar2019.csv',\n",
       " 'data/bikes\\\\155JourneyDataExtract27Mar2019-02Apr2019.csv',\n",
       " 'data/bikes\\\\156JourneyDataExtract03Apr2019-09Apr2019.csv',\n",
       " 'data/bikes\\\\157JourneyDataExtract10Apr2019-16Apr2019.csv',\n",
       " 'data/bikes\\\\158JourneyDataExtract17Apr2019-23Apr2019.csv',\n",
       " 'data/bikes\\\\159JourneyDataExtract24Apr2019-30Apr2019.csv',\n",
       " 'data/bikes\\\\15JourneyDataExtract20Jul2016-26Jul2016.csv',\n",
       " 'data/bikes\\\\16. Journey Data Extract 01Oct-31Oct12.csv',\n",
       " 'data/bikes\\\\160JourneyDataExtract01May2019-07May2019.csv',\n",
       " 'data/bikes\\\\161JourneyDataExtract08May2019-14May2019.csv',\n",
       " 'data/bikes\\\\162JourneyDataExtract15May2019-21May2019.csv',\n",
       " 'data/bikes\\\\163JourneyDataExtract22May2019-28May2019.csv',\n",
       " 'data/bikes\\\\164JourneyDataExtract29May2019-04Jun2019.csv',\n",
       " 'data/bikes\\\\165JourneyDataExtract05Jun2019-11Jun2019.csv',\n",
       " 'data/bikes\\\\166JourneyDataExtract12Jun2019-18Jun2019.csv',\n",
       " 'data/bikes\\\\167JourneyDataExtract19Jun2019-25Jun2019.csv',\n",
       " 'data/bikes\\\\168JourneyDataExtract26Jun2019-02Jul2019.csv',\n",
       " 'data/bikes\\\\169JourneyDataExtract03Jul2019-09Jul2019.csv',\n",
       " 'data/bikes\\\\16JourneyDataExtract27Jul2016-02Aug2016.csv',\n",
       " 'data/bikes\\\\17. Journey Data Extract 01Nov-30Nov12.csv',\n",
       " 'data/bikes\\\\170JourneyDataExtract10Jul2019-16Jul2019.csv',\n",
       " 'data/bikes\\\\171JourneyDataExtract17Jul2019-23Jul2019.csv',\n",
       " 'data/bikes\\\\172JourneyDataExtract24Jul2019-30Jul2019.csv',\n",
       " 'data/bikes\\\\173JourneyDataExtract31Jul2019-06Aug2019.csv',\n",
       " 'data/bikes\\\\174JourneyDataExtract07Aug2019-13Aug2019.csv',\n",
       " 'data/bikes\\\\175JourneyDataExtract14Aug2019-20Aug2019.csv',\n",
       " 'data/bikes\\\\176JourneyDataExtract21Aug2019-27Aug2019.csv',\n",
       " 'data/bikes\\\\177JourneyDataExtract28Aug2019-03Sep2019.csv',\n",
       " 'data/bikes\\\\178JourneyDataExtract04Sep2019-10Sep2019.csv',\n",
       " 'data/bikes\\\\179JourneyDataExtract11Sep2019-17Sep2019.csv',\n",
       " 'data/bikes\\\\17JourneyDataExtract03Aug2016-09Aug2016.csv',\n",
       " 'data/bikes\\\\18. Journey Data Extract 01Dec-31Dec12.csv',\n",
       " 'data/bikes\\\\180JourneyDataExtract18Sep2019-24Sep2019.csv',\n",
       " 'data/bikes\\\\181JourneyDataExtract25Sep2019-01Oct2019.csv',\n",
       " 'data/bikes\\\\182JourneyDataExtract02Oct2019-08Oct2019.csv',\n",
       " 'data/bikes\\\\183JourneyDataExtract09Oct2019-15Oct2019.csv',\n",
       " 'data/bikes\\\\184JourneyDataExtract16Oct2019-22Oct2019.csv',\n",
       " 'data/bikes\\\\185JourneyDataExtract23Oct2019-29Oct2019.csv',\n",
       " 'data/bikes\\\\186JourneyDataExtract30Oct2019-05Nov2019.csv',\n",
       " 'data/bikes\\\\187JourneyDataExtract06Nov2019-12Nov2019.csv',\n",
       " 'data/bikes\\\\188JourneyDataExtract13Nov2019-19Nov2019.csv',\n",
       " 'data/bikes\\\\189JourneyDataExtract20Nov2019-26Nov2019.csv',\n",
       " 'data/bikes\\\\18JourneyDataExtract10Aug2016-16Aug2016.csv',\n",
       " 'data/bikes\\\\190JourneyDataExtract27Nov2019-03Dec2019.csv',\n",
       " 'data/bikes\\\\191JourneyDataExtract04Dec2019-10Dec2019.csv',\n",
       " 'data/bikes\\\\192JourneyDataExtract11Dec2019-17Dec2019.csv',\n",
       " 'data/bikes\\\\193JourneyDataExtract18Dec2019-24Dec2019.csv',\n",
       " 'data/bikes\\\\194JourneyDataExtract25Dec2019-31Dec2019.csv',\n",
       " 'data/bikes\\\\19JourneyDataExtract17Aug2016-23Aug2016.csv',\n",
       " 'data/bikes\\\\1a.JourneyDataExtract04Jan15-17Jan15.csv',\n",
       " 'data/bikes\\\\1b.JourneyDataExtract18Jan15-31Jan15.csv',\n",
       " 'data/bikes\\\\2. Journey Data Extract 03Feb14-01Mar14.csv',\n",
       " 'data/bikes\\\\2. Journey Data Extract 06Jan-02Feb13.csv',\n",
       " 'data/bikes\\\\2. Journey Data Extract_01Feb-29Feb 12.csv',\n",
       " 'data/bikes\\\\20JourneyDataExtract24Aug2016-30Aug2016.csv',\n",
       " 'data/bikes\\\\21JourneyDataExtract31Aug2016-06Sep2016.csv',\n",
       " 'data/bikes\\\\22JourneyDataExtract07Sep2016-13Sep2016.csv',\n",
       " 'data/bikes\\\\23JourneyDataExtract14Sep2016-20Sep2016.csv',\n",
       " 'data/bikes\\\\24JourneyDataExtract21Sep2016-27Sep2016.csv',\n",
       " 'data/bikes\\\\25JourneyDataExtract28Sep2016-04Oct2016.csv',\n",
       " 'data/bikes\\\\26JourneyDataExtract05Oct2016-11Oct2016.csv',\n",
       " 'data/bikes\\\\27JourneyDataExtract12Oct2016-18Oct2016.csv',\n",
       " 'data/bikes\\\\28JourneyDataExtract19Oct2016-25Oct2016.csv',\n",
       " 'data/bikes\\\\298JourneyDataExtract29Dec2021-04Jan2022.csv',\n",
       " 'data/bikes\\\\299JourneyDataExtract05Jan2022-11Jan2022.csv',\n",
       " 'data/bikes\\\\29JourneyDataExtract26Oct2016-01Nov2016.csv',\n",
       " 'data/bikes\\\\2a.JourneyDataExtract01Feb15-14Feb15.csv',\n",
       " 'data/bikes\\\\2b.JourneyDataExtract15Feb15-28Feb15.csv',\n",
       " 'data/bikes\\\\3. Journey Data Extract 02Mar14-31Mar14.csv',\n",
       " 'data/bikes\\\\3. Journey Data Extract 03Feb-02Mar13.csv',\n",
       " 'data/bikes\\\\3. Journey Data Extract_01Mar-31Mar12.csv',\n",
       " 'data/bikes\\\\300JourneyDataExtract12Jan2022-18Jan2022.csv',\n",
       " 'data/bikes\\\\301JourneyDataExtract19Jan2022-25Jan2022.csv',\n",
       " 'data/bikes\\\\302JourneyDataExtract26Jan2022-01Feb2022.csv',\n",
       " 'data/bikes\\\\303JourneyDataExtract02Feb2022-08Feb2022.csv',\n",
       " 'data/bikes\\\\304JourneyDataExtract09Feb2022-15Feb2022.csv',\n",
       " 'data/bikes\\\\305JourneyDataExtract16Feb2022-22Feb2022.csv',\n",
       " 'data/bikes\\\\306JourneyDataExtract23Feb2022-01Mar2022.csv',\n",
       " 'data/bikes\\\\307JourneyDataExtract02Mar2022-08Mar2022.csv',\n",
       " 'data/bikes\\\\308JourneyDataExtract09Mar2022-15Mar2022.csv',\n",
       " 'data/bikes\\\\309JourneyDataExtract16Mar2022-22Mar2022.csv',\n",
       " 'data/bikes\\\\30JourneyDataExtract02Nov2016-08Nov2016.csv',\n",
       " 'data/bikes\\\\310JourneyDataExtract23Mar2022-29Mar2022.csv',\n",
       " 'data/bikes\\\\311JourneyDataExtract30Mar2022-05Apr2022.csv',\n",
       " 'data/bikes\\\\312JourneyDataExtract06Apr2022-12Apr2022.csv',\n",
       " 'data/bikes\\\\313JourneyDataExtract13Apr2022-19Apr2022.csv',\n",
       " 'data/bikes\\\\314JourneyDataExtract20Apr2022-26Apr2022.csv',\n",
       " 'data/bikes\\\\315JourneyDataExtract27Apr2022-03May2022.csv',\n",
       " 'data/bikes\\\\316JourneyDataExtract04May2022-10May2022.csv',\n",
       " 'data/bikes\\\\317JourneyDataExtract11May2022-17May2022.csv',\n",
       " 'data/bikes\\\\318JourneyDataExtract18May2022-24May2022.csv',\n",
       " 'data/bikes\\\\319JourneyDataExtract25May2022-31May2022.csv',\n",
       " 'data/bikes\\\\31JourneyDataExtract09Nov2016-15Nov2016.csv',\n",
       " 'data/bikes\\\\320JourneyDataExtract01Jun2022-07Jun2022.csv',\n",
       " 'data/bikes\\\\321JourneyDataExtract08Jun2022-14Jun2022.csv',\n",
       " 'data/bikes\\\\322JourneyDataExtract15Jun2022-21Jun2022.csv',\n",
       " 'data/bikes\\\\323JourneyDataExtract22Jun2022-28Jun2022.csv',\n",
       " 'data/bikes\\\\324JourneyDataExtract29Jun2022-05Jul2022.csv',\n",
       " 'data/bikes\\\\325JourneyDataExtract06Jul2022-12Jul2022.csv',\n",
       " 'data/bikes\\\\326JourneyDataExtract13Jul2022-19Jul2022.csv',\n",
       " 'data/bikes\\\\327JourneyDataExtract20Jul2022-26Jul2022.csv',\n",
       " 'data/bikes\\\\328JourneyDataExtract27Jul2022-02Aug2022.csv',\n",
       " 'data/bikes\\\\329JourneyDataExtract03Aug2022-09Aug2022.csv',\n",
       " 'data/bikes\\\\32JourneyDataExtract16Nov2016-22Nov2016.csv',\n",
       " 'data/bikes\\\\330JourneyDataExtract10Aug2022-16Aug2022.csv',\n",
       " 'data/bikes\\\\331JourneyDataExtract17Aug2022-23Aug2022.csv',\n",
       " 'data/bikes\\\\332JourneyDataExtract24Aug2022-30Aug2022.csv',\n",
       " 'data/bikes\\\\333JourneyDataExtract31Aug2022-06Sep2022.csv',\n",
       " 'data/bikes\\\\334JourneyDataExtract07Sep2022-11Sep2022.csv',\n",
       " 'data/bikes\\\\335JourneyDataExtract12Sep2022-18Sep2022.csv',\n",
       " 'data/bikes\\\\336JourneyDataExtract19Sep2022-25Sep2022.csv',\n",
       " 'data/bikes\\\\337JourneyDataExtract26Sep2022-02Oct2022.csv',\n",
       " 'data/bikes\\\\338JourneyDataExtract03Oct2022-09Oct2022.csv',\n",
       " 'data/bikes\\\\339JourneyDataExtract10Oct2022-16Oct2022.csv',\n",
       " 'data/bikes\\\\33JourneyDataExtract23Nov2016-29Nov2016.csv',\n",
       " 'data/bikes\\\\340JourneyDataExtract17Oct2022-23Oct2022.csv',\n",
       " 'data/bikes\\\\341JourneyDataExtract24Oct2022-30Oct2022.csv',\n",
       " 'data/bikes\\\\342JourneyDataExtract31Oct2022-06Nov2022.csv',\n",
       " 'data/bikes\\\\343JourneyDataExtract07Nov2022-13Nov2022.csv',\n",
       " 'data/bikes\\\\344JourneyDataExtract14Nov2022-20Nov2022.csv',\n",
       " 'data/bikes\\\\345JourneyDataExtract21Nov2022-27Nov2022.csv',\n",
       " 'data/bikes\\\\346JourneyDataExtract28Nov2022-04Dec2022.csv',\n",
       " 'data/bikes\\\\347JourneyDataExtract05Dec2022-11Dec2022.csv',\n",
       " 'data/bikes\\\\348JourneyDataExtract12Dec2022-18Dec2022.csv',\n",
       " 'data/bikes\\\\349JourneyDataExtract19Dec2022-25Dec2022.csv',\n",
       " 'data/bikes\\\\34JourneyDataExtract30Nov2016-06Dec2016.csv',\n",
       " 'data/bikes\\\\350JourneyDataExtract26Dec2022-01Jan2023.csv',\n",
       " 'data/bikes\\\\35JourneyDataExtract07Dec2016-13Dec2016.csv',\n",
       " 'data/bikes\\\\36JourneyDataExtract14Dec2016-20Dec2016.csv',\n",
       " 'data/bikes\\\\37JourneyDataExtract21Dec2016-27Dec2016.csv',\n",
       " 'data/bikes\\\\38JourneyDataExtract28Dec2016-03Jan2017.csv',\n",
       " 'data/bikes\\\\39JourneyDataExtract04Jan2017-10Jan2017.csv',\n",
       " 'data/bikes\\\\3a.JourneyDataExtract01Mar15-15Mar15.csv',\n",
       " 'data/bikes\\\\3b.JourneyDataExtract16Mar15-31Mar15.csv',\n",
       " 'data/bikes\\\\4. Journey Data Extract 01Apr14-26Apr14.csv',\n",
       " 'data/bikes\\\\4. Journey Data Extract 03Mar-31Mar13.csv',\n",
       " 'data/bikes\\\\4. Journey Data Extract_1Apr-28Apr12.csv',\n",
       " 'data/bikes\\\\40JourneyDataExtract11Jan2017-17Jan2017.csv',\n",
       " 'data/bikes\\\\41JourneyDataExtract18Jan2017-24Jan2017.csv',\n",
       " 'data/bikes\\\\42JourneyDataExtract25Jan2017-31Jan2017.csv',\n",
       " 'data/bikes\\\\43JourneyDataExtract01Feb2017-07Feb2017.csv',\n",
       " 'data/bikes\\\\44JourneyDataExtract08Feb2017-14Feb2017.csv',\n",
       " 'data/bikes\\\\45JourneyDataExtract15Feb2017-21Feb2017.csv',\n",
       " 'data/bikes\\\\46JourneyDataExtract22Feb2017-28Feb2017.csv',\n",
       " 'data/bikes\\\\47JourneyDataExtract01Mar2017-07Mar2017.csv',\n",
       " 'data/bikes\\\\48JourneyDataExtract08Mar2017-14Mar2017.csv',\n",
       " 'data/bikes\\\\49JourneyDataExtract15Mar2017-21Mar2017.csv',\n",
       " 'data/bikes\\\\4a.JourneyDataExtract01Apr15-16Apr15.csv',\n",
       " 'data/bikes\\\\4b.JourneyDataExtract 17Apr15-02May15.csv',\n",
       " 'data/bikes\\\\5. Journey Data Extract 01Apr-27Apr13.csv',\n",
       " 'data/bikes\\\\5. Journey Data Extract 27Apr14-24May14.csv',\n",
       " 'data/bikes\\\\5. Journey Data Extract_29Apr-26May12.csv',\n",
       " 'data/bikes\\\\50 Journey Data Extract 22Mar2017-28Mar2017.csv',\n",
       " 'data/bikes\\\\51 Journey Data Extract 29Mar2017-04Apr2017.csv',\n",
       " 'data/bikes\\\\52 Journey Data Extract 05Apr2017-11Apr2017.csv',\n",
       " 'data/bikes\\\\53JourneyDataExtract12Apr2017-18Apr2017.csv',\n",
       " 'data/bikes\\\\54JourneyDataExtract19Apr2017-25Apr2017.csv',\n",
       " 'data/bikes\\\\55JourneyData Extract26Apr2017-02May2017.csv',\n",
       " 'data/bikes\\\\56JourneyDataExtract 03May2017-09May2017.csv',\n",
       " 'data/bikes\\\\57JourneyDataExtract10May2017-16May2017.csv',\n",
       " 'data/bikes\\\\5a.JourneyDataExtract03May15-16May15.csv',\n",
       " 'data/bikes\\\\5b.JourneyDataExtract17May15-30May15.csv',\n",
       " 'data/bikes\\\\6. Journey Data Extract 25May14-21Jun14.csv',\n",
       " 'data/bikes\\\\6. Journey Data Extract 28Apr-25May13.csv',\n",
       " 'data/bikes\\\\6. Journey Data Extract_27May-23Jun12.csv',\n",
       " 'data/bikes\\\\6aJourneyDataExtract31May15-12Jun15.csv',\n",
       " 'data/bikes\\\\6bJourneyDataExtract13Jun15-27Jun15.csv',\n",
       " 'data/bikes\\\\7. Journey Data Extract 22Jun14-19Jul14.csv',\n",
       " 'data/bikes\\\\7. Journey Data Extract 26May-22Jun13.csv',\n",
       " 'data/bikes\\\\7. Journey Data Extract_24Jun-21Jul12.csv',\n",
       " 'data/bikes\\\\7a.JourneyDataExtract28Jun15-11Jul15.csv',\n",
       " 'data/bikes\\\\7b.JourneyDataExtract12Jul15-25Jul15.csv',\n",
       " 'data/bikes\\\\8. Journey Data Extract 22Jul-18Aug12.csv',\n",
       " 'data/bikes\\\\8. Journey Data Extract 23Jun-20Jul13.csv',\n",
       " 'data/bikes\\\\8a Journey Data Extract 20Jul14-31Jul14.csv',\n",
       " 'data/bikes\\\\8aJourneyDataExtract26Jul15-07Aug15.csv',\n",
       " 'data/bikes\\\\8b Journey Data Extract 01Aug14-16Aug14.csv',\n",
       " 'data/bikes\\\\8bJourneyData Extract 08Aug15-22Aug15.csv',\n",
       " 'data/bikes\\\\9. Journey Data Extract 19Aug-20 Aug12.csv',\n",
       " 'data/bikes\\\\9. Journey Data Extract 21Jul-17Aug13.csv',\n",
       " 'data/bikes\\\\9a Journey Data Extract 17Aug14-31Aug14.csv',\n",
       " 'data/bikes\\\\9a-Journey-Data-Extract-23Aug15-05Sep15.csv',\n",
       " 'data/bikes\\\\9b Journey Data Extract 01Sep14-13Sep14.csv',\n",
       " 'data/bikes\\\\9b-Journey-Data-Extract-06Sep15-19Sep15.csv']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob \n",
    "\n",
    "# using glob to list all the csv file in the bikefolder filepath\n",
    "all_csv = glob(bikefolder+str('/*.csv'))\n",
    "all_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of csv files that contain '2019' and '2022' respectively\n",
    "csv_2019 = [item for item in all_csv if '2019' in item]\n",
    "csv_2017 = [item for item in all_csv if '2017' in item]\n",
    "csv_2022 = [item for item in all_csv if '2022' in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using list comprehension that reads each csv file from the list and gnerators a sequence of dataframes\n",
    "dfs = (pd.read_csv(csv) for csv in csv_2019)\n",
    "\n",
    "# concatenate csvs them into a single DataFrame using pd.concat()\n",
    "# ignore_index=True parameter resets the index of the resulting DataFrame, so that it is a continuous sequence of integers.\n",
    "data_2019 = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing the same for the 2022 data\n",
    "# passing errors within the csv files as per https://stackoverflow.com/questions/52105659/pandas-read-csv-unexpected-end-of-data-error\n",
    "dfs_2022 = (pd.read_csv(csv, engine='python', encoding='utf-8', on_bad_lines='skip') for csv in csv_2022)\n",
    "data_2022 = pd.concat(dfs_2022, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10388411, 9)\n",
      "(11232181, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rental Id</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Bike Id</th>\n",
       "      <th>End Date</th>\n",
       "      <th>EndStation Id</th>\n",
       "      <th>EndStation Name</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>StartStation Id</th>\n",
       "      <th>StartStation Name</th>\n",
       "      <th>Number</th>\n",
       "      <th>Start date</th>\n",
       "      <th>Start station number</th>\n",
       "      <th>Start station</th>\n",
       "      <th>End date</th>\n",
       "      <th>End station number</th>\n",
       "      <th>End station</th>\n",
       "      <th>Bike number</th>\n",
       "      <th>Bike model</th>\n",
       "      <th>Total duration</th>\n",
       "      <th>Total duration (ms)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115967515.0</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>15338.0</td>\n",
       "      <td>01/01/2022 23:13</td>\n",
       "      <td>310.0</td>\n",
       "      <td>Black Prince Road, Vauxhall</td>\n",
       "      <td>01/01/2022 22:52</td>\n",
       "      <td>529.0</td>\n",
       "      <td>Manresa Road, Chelsea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>116017034.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>19861.0</td>\n",
       "      <td>04/01/2022 19:08</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Brunswick Square, Bloomsbury</td>\n",
       "      <td>04/01/2022 18:56</td>\n",
       "      <td>804.0</td>\n",
       "      <td>Good's Way, King's Cross</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115895660.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>19666.0</td>\n",
       "      <td>29/12/2021 16:34</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Calshot Street , King's Cross</td>\n",
       "      <td>29/12/2021 16:28</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Guilford Street , Bloomsbury</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116016563.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>19861.0</td>\n",
       "      <td>04/01/2022 18:46</td>\n",
       "      <td>804.0</td>\n",
       "      <td>Good's Way, King's Cross</td>\n",
       "      <td>04/01/2022 18:38</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Guilford Street , Bloomsbury</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>116014412.0</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>17235.0</td>\n",
       "      <td>04/01/2022 17:45</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Belgrove Street , King's Cross</td>\n",
       "      <td>04/01/2022 17:24</td>\n",
       "      <td>297.0</td>\n",
       "      <td>Geraldine Street, Elephant &amp; Castle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rental Id  Duration  Bike Id          End Date  EndStation Id  \\\n",
       "0  115967515.0    1260.0  15338.0  01/01/2022 23:13          310.0   \n",
       "1  116017034.0     720.0  19861.0  04/01/2022 19:08           11.0   \n",
       "2  115895660.0     360.0  19666.0  29/12/2021 16:34           70.0   \n",
       "3  116016563.0     480.0  19861.0  04/01/2022 18:46          804.0   \n",
       "4  116014412.0    1260.0  17235.0  04/01/2022 17:45           14.0   \n",
       "\n",
       "                  EndStation Name        Start Date  StartStation Id  \\\n",
       "0     Black Prince Road, Vauxhall  01/01/2022 22:52            529.0   \n",
       "1    Brunswick Square, Bloomsbury  04/01/2022 18:56            804.0   \n",
       "2   Calshot Street , King's Cross  29/12/2021 16:28             57.0   \n",
       "3        Good's Way, King's Cross  04/01/2022 18:38             57.0   \n",
       "4  Belgrove Street , King's Cross  04/01/2022 17:24            297.0   \n",
       "\n",
       "                     StartStation Name  Number Start date  \\\n",
       "0                Manresa Road, Chelsea     NaN        NaN   \n",
       "1             Good's Way, King's Cross     NaN        NaN   \n",
       "2         Guilford Street , Bloomsbury     NaN        NaN   \n",
       "3         Guilford Street , Bloomsbury     NaN        NaN   \n",
       "4  Geraldine Street, Elephant & Castle     NaN        NaN   \n",
       "\n",
       "  Start station number Start station End date End station number End station  \\\n",
       "0                  NaN           NaN      NaN                NaN         NaN   \n",
       "1                  NaN           NaN      NaN                NaN         NaN   \n",
       "2                  NaN           NaN      NaN                NaN         NaN   \n",
       "3                  NaN           NaN      NaN                NaN         NaN   \n",
       "4                  NaN           NaN      NaN                NaN         NaN   \n",
       "\n",
       "   Bike number Bike model Total duration  Total duration (ms)  \n",
       "0          NaN        NaN            NaN                  NaN  \n",
       "1          NaN        NaN            NaN                  NaN  \n",
       "2          NaN        NaN            NaN                  NaN  \n",
       "3          NaN        NaN            NaN                  NaN  \n",
       "4          NaN        NaN            NaN                  NaN  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data_2019.shape)\n",
    "data_2019.head()\n",
    "print(data_2022.shape)\n",
    "data_2022.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rental Id</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Bike Id</th>\n",
       "      <th>End Date</th>\n",
       "      <th>EndStation Id</th>\n",
       "      <th>EndStation Name</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>StartStation Id</th>\n",
       "      <th>StartStation Name</th>\n",
       "      <th>Start Date Converted</th>\n",
       "      <th>Hours</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83252102</td>\n",
       "      <td>720</td>\n",
       "      <td>2077</td>\n",
       "      <td>31/12/2018 19:05</td>\n",
       "      <td>272</td>\n",
       "      <td>Baylis Road, Waterloo</td>\n",
       "      <td>31/12/2018 18:53</td>\n",
       "      <td>94</td>\n",
       "      <td>Bricklayers Arms, Borough</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83195883</td>\n",
       "      <td>120</td>\n",
       "      <td>10781</td>\n",
       "      <td>27/12/2018 19:47</td>\n",
       "      <td>93</td>\n",
       "      <td>Cloudesley Road, Angel</td>\n",
       "      <td>27/12/2018 19:45</td>\n",
       "      <td>339</td>\n",
       "      <td>Risinghill Street, Angel</td>\n",
       "      <td>2018-12-27</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83196070</td>\n",
       "      <td>120</td>\n",
       "      <td>2977</td>\n",
       "      <td>27/12/2018 20:11</td>\n",
       "      <td>339</td>\n",
       "      <td>Risinghill Street, Angel</td>\n",
       "      <td>27/12/2018 20:09</td>\n",
       "      <td>234</td>\n",
       "      <td>Liverpool Road (N1 Centre), Angel</td>\n",
       "      <td>2018-12-27</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83197932</td>\n",
       "      <td>660</td>\n",
       "      <td>10802</td>\n",
       "      <td>28/12/2018 07:35</td>\n",
       "      <td>282</td>\n",
       "      <td>Royal London Hospital, Whitechapel</td>\n",
       "      <td>28/12/2018 07:24</td>\n",
       "      <td>698</td>\n",
       "      <td>Shoreditch Court, Haggerston</td>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83176351</td>\n",
       "      <td>1380</td>\n",
       "      <td>15749</td>\n",
       "      <td>26/12/2018 11:55</td>\n",
       "      <td>785</td>\n",
       "      <td>Aquatic Centre, Queen Elizabeth Olympic Park</td>\n",
       "      <td>26/12/2018 11:32</td>\n",
       "      <td>783</td>\n",
       "      <td>Monier Road, Hackney Wick</td>\n",
       "      <td>2018-12-26</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rental Id  Duration  Bike Id          End Date  EndStation Id  \\\n",
       "0   83252102       720     2077  31/12/2018 19:05            272   \n",
       "1   83195883       120    10781  27/12/2018 19:47             93   \n",
       "2   83196070       120     2977  27/12/2018 20:11            339   \n",
       "3   83197932       660    10802  28/12/2018 07:35            282   \n",
       "4   83176351      1380    15749  26/12/2018 11:55            785   \n",
       "\n",
       "                                EndStation Name        Start Date  \\\n",
       "0                         Baylis Road, Waterloo  31/12/2018 18:53   \n",
       "1                        Cloudesley Road, Angel  27/12/2018 19:45   \n",
       "2                      Risinghill Street, Angel  27/12/2018 20:09   \n",
       "3            Royal London Hospital, Whitechapel  28/12/2018 07:24   \n",
       "4  Aquatic Centre, Queen Elizabeth Olympic Park  26/12/2018 11:32   \n",
       "\n",
       "   StartStation Id                  StartStation Name Start Date Converted  \\\n",
       "0               94          Bricklayers Arms, Borough           2018-12-31   \n",
       "1              339           Risinghill Street, Angel           2018-12-27   \n",
       "2              234  Liverpool Road (N1 Centre), Angel           2018-12-27   \n",
       "3              698       Shoreditch Court, Haggerston           2018-12-28   \n",
       "4              783          Monier Road, Hackney Wick           2018-12-26   \n",
       "\n",
       "   Hours  Day  \n",
       "0     18    0  \n",
       "1     19    3  \n",
       "2     20    3  \n",
       "3      7    4  \n",
       "4     11    2  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2019\n",
    "\n",
    "## Add some extra variables to the dataset for use later in filtering\n",
    "\n",
    "import datetime\n",
    "\n",
    "## Feeding a specififed date format speeds up the pd.to_datetime function immeasurably, especially over large datasets\n",
    "## e.g. http://stackoverflow.com/questions/32034689/why-is-pandas-to-datetime-slow-for-non-standard-time-format-such-as-2014-12-31\n",
    "\n",
    "format = \"%d/%m/%Y %H:%M\"\n",
    "\n",
    "## Some routes had dates with a seconds component, whereas some didn't - the below code cuts these seconds off\n",
    "data_2019['Start Date']= data_2019['Start Date'].str[:16]\n",
    "\n",
    "data_2019['Start Date Converted']= pd.to_datetime(data_2019['Start Date'], format=format).dt.date\n",
    "\n",
    "data_2019['Hours']= pd.to_datetime(data_2019['Start Date'], format=format).dt.hour\n",
    "\n",
    "data_2019['Day']= pd.to_datetime(data_2019['Start Date'], format=format).dt.weekday\n",
    "\n",
    "data_2019.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rental Id</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Bike Id</th>\n",
       "      <th>End Date</th>\n",
       "      <th>EndStation Id</th>\n",
       "      <th>EndStation Name</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>StartStation Id</th>\n",
       "      <th>StartStation Name</th>\n",
       "      <th>Number</th>\n",
       "      <th>Start date</th>\n",
       "      <th>Start station number</th>\n",
       "      <th>Start station</th>\n",
       "      <th>End date</th>\n",
       "      <th>End station number</th>\n",
       "      <th>End station</th>\n",
       "      <th>Bike number</th>\n",
       "      <th>Bike model</th>\n",
       "      <th>Total duration</th>\n",
       "      <th>Total duration (ms)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10300669</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126646858.0</td>\n",
       "      <td>2022-11-09 10:24</td>\n",
       "      <td>22180</td>\n",
       "      <td>Cheapside, Bank</td>\n",
       "      <td>2022-11-09 10:33</td>\n",
       "      <td>1151</td>\n",
       "      <td>Whitehall Place, Strand</td>\n",
       "      <td>60399.0</td>\n",
       "      <td>PBSC_EBIKE</td>\n",
       "      <td>9m 34s</td>\n",
       "      <td>574742.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9708807</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126117045.0</td>\n",
       "      <td>2022-10-19 21:42</td>\n",
       "      <td>300012</td>\n",
       "      <td>Irene Road, Parsons Green</td>\n",
       "      <td>2022-10-19 21:48</td>\n",
       "      <td>300058</td>\n",
       "      <td>The Vale, Chelsea</td>\n",
       "      <td>60402.0</td>\n",
       "      <td>PBSC_EBIKE</td>\n",
       "      <td>6m 3s</td>\n",
       "      <td>363321.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9856202</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126367091.0</td>\n",
       "      <td>2022-10-28 18:30</td>\n",
       "      <td>003467</td>\n",
       "      <td>Dock Street, Wapping</td>\n",
       "      <td>2022-10-28 18:56</td>\n",
       "      <td>200129</td>\n",
       "      <td>Charlotte Terrace, Angel</td>\n",
       "      <td>60130.0</td>\n",
       "      <td>PBSC_EBIKE</td>\n",
       "      <td>26m 0s</td>\n",
       "      <td>1560647.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9856197</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126367086.0</td>\n",
       "      <td>2022-10-28 18:30</td>\n",
       "      <td>000973</td>\n",
       "      <td>Bethnal Green Road, Shoreditch</td>\n",
       "      <td>2022-10-28 18:57</td>\n",
       "      <td>300009</td>\n",
       "      <td>World's End Place, West Chelsea</td>\n",
       "      <td>60150.0</td>\n",
       "      <td>PBSC_EBIKE</td>\n",
       "      <td>27m 14s</td>\n",
       "      <td>1634782.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10089427</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126498212.0</td>\n",
       "      <td>2022-11-02 16:14</td>\n",
       "      <td>1186</td>\n",
       "      <td>Belvedere Road 1, South Bank</td>\n",
       "      <td>2022-11-02 16:27</td>\n",
       "      <td>2667</td>\n",
       "      <td>Tower Wharf, Bermondsey</td>\n",
       "      <td>60272.0</td>\n",
       "      <td>PBSC_EBIKE</td>\n",
       "      <td>13m 20s</td>\n",
       "      <td>800924.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8677099</th>\n",
       "      <td>125044170.0</td>\n",
       "      <td>3840.0</td>\n",
       "      <td>21738.0</td>\n",
       "      <td>11/09/2022 09:45</td>\n",
       "      <td>201.0</td>\n",
       "      <td>Dorset Square, Marylebone</td>\n",
       "      <td>11/09/2022 08:41</td>\n",
       "      <td>514.0</td>\n",
       "      <td>Portman Square, Marylebone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8677100</th>\n",
       "      <td>125102716.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>10886.0</td>\n",
       "      <td>11/09/2022 10:19</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Sedding Street, Sloane Square</td>\n",
       "      <td>11/09/2022 10:13</td>\n",
       "      <td>826.0</td>\n",
       "      <td>Allington Street, Victoria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8677101</th>\n",
       "      <td>125102718.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>8719.0</td>\n",
       "      <td>11/09/2022 10:53</td>\n",
       "      <td>270.0</td>\n",
       "      <td>Kennington Lane Rail Bridge, Vauxhall</td>\n",
       "      <td>11/09/2022 10:44</td>\n",
       "      <td>826.0</td>\n",
       "      <td>Allington Street, Victoria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8677102</th>\n",
       "      <td>125044249.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>8881.0</td>\n",
       "      <td>11/09/2022 14:13</td>\n",
       "      <td>757.0</td>\n",
       "      <td>Harcourt Terrace, West Brompton</td>\n",
       "      <td>11/09/2022 12:33</td>\n",
       "      <td>757.0</td>\n",
       "      <td>Harcourt Terrace, West Brompton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8677103</th>\n",
       "      <td>125044312.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>23806.0</td>\n",
       "      <td>12/09/2022 00:06</td>\n",
       "      <td>339.0</td>\n",
       "      <td>Risinghill Street, Angel</td>\n",
       "      <td>11/09/2022 23:58</td>\n",
       "      <td>189.0</td>\n",
       "      <td>Claremont Square, Angel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11232181 rows  20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Rental Id  Duration  Bike Id          End Date  EndStation Id  \\\n",
       "10300669          NaN       NaN      NaN               NaN            NaN   \n",
       "9708807           NaN       NaN      NaN               NaN            NaN   \n",
       "9856202           NaN       NaN      NaN               NaN            NaN   \n",
       "9856197           NaN       NaN      NaN               NaN            NaN   \n",
       "10089427          NaN       NaN      NaN               NaN            NaN   \n",
       "...               ...       ...      ...               ...            ...   \n",
       "8677099   125044170.0    3840.0  21738.0  11/09/2022 09:45          201.0   \n",
       "8677100   125102716.0     360.0  10886.0  11/09/2022 10:19            5.0   \n",
       "8677101   125102718.0     540.0   8719.0  11/09/2022 10:53          270.0   \n",
       "8677102   125044249.0    6000.0   8881.0  11/09/2022 14:13          757.0   \n",
       "8677103   125044312.0     480.0  23806.0  12/09/2022 00:06          339.0   \n",
       "\n",
       "                                EndStation Name        Start Date  \\\n",
       "10300669                                    NaN               NaN   \n",
       "9708807                                     NaN               NaN   \n",
       "9856202                                     NaN               NaN   \n",
       "9856197                                     NaN               NaN   \n",
       "10089427                                    NaN               NaN   \n",
       "...                                         ...               ...   \n",
       "8677099               Dorset Square, Marylebone  11/09/2022 08:41   \n",
       "8677100           Sedding Street, Sloane Square  11/09/2022 10:13   \n",
       "8677101   Kennington Lane Rail Bridge, Vauxhall  11/09/2022 10:44   \n",
       "8677102         Harcourt Terrace, West Brompton  11/09/2022 12:33   \n",
       "8677103                Risinghill Street, Angel  11/09/2022 23:58   \n",
       "\n",
       "          StartStation Id                StartStation Name       Number  \\\n",
       "10300669              NaN                              NaN  126646858.0   \n",
       "9708807               NaN                              NaN  126117045.0   \n",
       "9856202               NaN                              NaN  126367091.0   \n",
       "9856197               NaN                              NaN  126367086.0   \n",
       "10089427              NaN                              NaN  126498212.0   \n",
       "...                   ...                              ...          ...   \n",
       "8677099             514.0       Portman Square, Marylebone          NaN   \n",
       "8677100             826.0       Allington Street, Victoria          NaN   \n",
       "8677101             826.0       Allington Street, Victoria          NaN   \n",
       "8677102             757.0  Harcourt Terrace, West Brompton          NaN   \n",
       "8677103             189.0          Claremont Square, Angel          NaN   \n",
       "\n",
       "                Start date Start station number  \\\n",
       "10300669  2022-11-09 10:24                22180   \n",
       "9708807   2022-10-19 21:42               300012   \n",
       "9856202   2022-10-28 18:30               003467   \n",
       "9856197   2022-10-28 18:30               000973   \n",
       "10089427  2022-11-02 16:14                 1186   \n",
       "...                    ...                  ...   \n",
       "8677099                NaN                  NaN   \n",
       "8677100                NaN                  NaN   \n",
       "8677101                NaN                  NaN   \n",
       "8677102                NaN                  NaN   \n",
       "8677103                NaN                  NaN   \n",
       "\n",
       "                           Start station          End date End station number  \\\n",
       "10300669                 Cheapside, Bank  2022-11-09 10:33               1151   \n",
       "9708807        Irene Road, Parsons Green  2022-10-19 21:48             300058   \n",
       "9856202             Dock Street, Wapping  2022-10-28 18:56             200129   \n",
       "9856197   Bethnal Green Road, Shoreditch  2022-10-28 18:57             300009   \n",
       "10089427    Belvedere Road 1, South Bank  2022-11-02 16:27               2667   \n",
       "...                                  ...               ...                ...   \n",
       "8677099                              NaN               NaN                NaN   \n",
       "8677100                              NaN               NaN                NaN   \n",
       "8677101                              NaN               NaN                NaN   \n",
       "8677102                              NaN               NaN                NaN   \n",
       "8677103                              NaN               NaN                NaN   \n",
       "\n",
       "                              End station  Bike number  Bike model  \\\n",
       "10300669          Whitehall Place, Strand      60399.0  PBSC_EBIKE   \n",
       "9708807                 The Vale, Chelsea      60402.0  PBSC_EBIKE   \n",
       "9856202          Charlotte Terrace, Angel      60130.0  PBSC_EBIKE   \n",
       "9856197   World's End Place, West Chelsea      60150.0  PBSC_EBIKE   \n",
       "10089427          Tower Wharf, Bermondsey      60272.0  PBSC_EBIKE   \n",
       "...                                   ...          ...         ...   \n",
       "8677099                               NaN          NaN         NaN   \n",
       "8677100                               NaN          NaN         NaN   \n",
       "8677101                               NaN          NaN         NaN   \n",
       "8677102                               NaN          NaN         NaN   \n",
       "8677103                               NaN          NaN         NaN   \n",
       "\n",
       "         Total duration  Total duration (ms)  \n",
       "10300669         9m 34s             574742.0  \n",
       "9708807           6m 3s             363321.0  \n",
       "9856202          26m 0s            1560647.0  \n",
       "9856197         27m 14s            1634782.0  \n",
       "10089427        13m 20s             800924.0  \n",
       "...                 ...                  ...  \n",
       "8677099             NaN                  NaN  \n",
       "8677100             NaN                  NaN  \n",
       "8677101             NaN                  NaN  \n",
       "8677102             NaN                  NaN  \n",
       "8677103             NaN                  NaN  \n",
       "\n",
       "[11232181 rows x 20 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2022.shape\n",
    "\n",
    "#data_2022.sort_values(by='End date', ascending=True)\n",
    "data_2022.sort_values(by='Bike model', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2022\n",
    "\n",
    "# In September 2022 the column names change slightly and additional clumns have been added\n",
    "# for example the 'Bike model' column has been added (classic or PBSC_EBIKE)\n",
    "\n",
    "# Let's clean this up and get all the data into single columns\n",
    "# transfering values from one pandas column to another pandas column only for null rows\n",
    "\n",
    "#creating a copy of the orginal data\n",
    "data_2022_clean = data_2022.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2022_clean.loc[data_2022_clean['Rental Id'].isnull(), 'Rental Id'] = data_2022_clean['Number']\n",
    "# converting from milliseconds to seconds, multipyling by 1000 \n",
    "data_2022_clean.loc[data_2022_clean['Duration'].isnull(), 'Duration'] = data_2022_clean['Total duration (ms)'] / 1000\n",
    "data_2022_clean.loc[data_2022_clean['Bike Id'].isnull(), 'Bike Id'] = data_2022_clean['Bike number']\n",
    "data_2022_clean.loc[data_2022_clean['End Date'].isnull(), 'End Date'] = data_2022_clean['End date']\n",
    "#data_2022_clean.loc[data_2022_clean['EndStation Id'].isnull(), 'EndStation Id'] = data_2022_clean['End station number']\n",
    "data_2022_clean.loc[data_2022_clean['EndStation Name'].isnull(), 'EndStation Name'] = data_2022_clean['End station']\n",
    "data_2022_clean.loc[data_2022_clean['Start Date'].isnull(), 'Start Date'] = data_2022_clean['Start date']\n",
    "#data_2022_clean.loc[data_2022_clean['StartStation Id'].isnull(), 'StartStation Id'] = data_2022_clean['End station number']\n",
    "data_2022_clean.loc[data_2022_clean['StartStation Name'].isnull(), 'StartStation Name'] = data_2022_clean['Start station']\n",
    "\n",
    "#data_2022_clean.sort_values(by='Bike model', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Docking station id also recorded differently from September 2022...\n",
    "# before September station id is associated with the id value in the xml below\n",
    "# however after September, station id is associated with terminalName value in the xml below\n",
    "# https://tfl.gov.uk/tfl/syndication/feeds/cycle-hire/livecyclehireupdates.xml\n",
    "\n",
    "# for example docking station, 'Chepside Bank' has an id of 427 and a terminal name of 022180\n",
    "#data_2022_clean.loc[data_2022_clean['EndStation Id'] == 427.0]\n",
    "#data_2022_clean.loc[data_2022_clean['End station number'] == 22180]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>terminal name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>River Street , Clerkenwell</td>\n",
       "      <td>1</td>\n",
       "      <td>1023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Phillimore Gardens, Kensington</td>\n",
       "      <td>2</td>\n",
       "      <td>1018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Christopher Street, Liverpool Street</td>\n",
       "      <td>3</td>\n",
       "      <td>1012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>St. Chad's Street, King's Cross</td>\n",
       "      <td>4</td>\n",
       "      <td>1013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sedding Street, Sloane Square</td>\n",
       "      <td>5</td>\n",
       "      <td>3420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   name  id  terminal name\n",
       "0            River Street , Clerkenwell   1           1023\n",
       "1        Phillimore Gardens, Kensington   2           1018\n",
       "2  Christopher Street, Liverpool Street   3           1012\n",
       "3       St. Chad's Street, King's Cross   4           1013\n",
       "4         Sedding Street, Sloane Square   5           3420"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the tfl xml, lets create a dataframe which includes name both docking station id and terminal name \n",
    "# we will then join it to the bike data dataframe to populate the missing data \n",
    "\n",
    "import requests\n",
    "from xml.etree import ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "site = \"https://tfl.gov.uk/tfl/syndication/feeds/cycle-hire/livecyclehireupdates.xml\"\n",
    "\n",
    "response = requests.get(site)\n",
    "root = ET.fromstring(response.content)\n",
    "\n",
    "id_list = [int(root[i][0].text) for i in range(0, len(root))]\n",
    "name_list = [root[i][1].text for i in range(0, len(root))]\n",
    "terminal_name_list = [int(root[i][2].text) for i in range(0, len(root))]\n",
    "df_id = pd.DataFrame(list(zip(name_list, id_list, terminal_name_list)), columns = [\"name\",\"id\",\"terminal name\"])\n",
    "\n",
    "# exporting as a csv\n",
    "#df_id.to_csv('output/docking_station_terminalname_id.csv', header=True)\n",
    "\n",
    "df_id.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining the the 2 dataframes dataframes based on the station names\n",
    "\n",
    "# let's populate the 'Endstation Id' column \n",
    "# joining the tables\n",
    "data_2022_clean = pd.merge(data_2022_clean, df_id, left_on='End station', right_on='name', how='outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populating table\n",
    "data_2022_clean.loc[data_2022_clean['EndStation Id'].isnull(), 'EndStation Id'] = data_2022_clean['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rental Id</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Bike Id</th>\n",
       "      <th>End Date</th>\n",
       "      <th>EndStation Id</th>\n",
       "      <th>EndStation Name</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>StartStation Id</th>\n",
       "      <th>StartStation Name</th>\n",
       "      <th>Number</th>\n",
       "      <th>...</th>\n",
       "      <th>End date</th>\n",
       "      <th>End station number</th>\n",
       "      <th>End station</th>\n",
       "      <th>Bike number</th>\n",
       "      <th>Bike model</th>\n",
       "      <th>Total duration</th>\n",
       "      <th>Total duration (ms)</th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>terminal name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115967515.0</td>\n",
       "      <td>1260.000</td>\n",
       "      <td>15338.0</td>\n",
       "      <td>01/01/2022 23:13</td>\n",
       "      <td>310.0</td>\n",
       "      <td>Black Prince Road, Vauxhall</td>\n",
       "      <td>01/01/2022 22:52</td>\n",
       "      <td>529.0</td>\n",
       "      <td>Manresa Road, Chelsea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>116017034.0</td>\n",
       "      <td>720.000</td>\n",
       "      <td>19861.0</td>\n",
       "      <td>04/01/2022 19:08</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Brunswick Square, Bloomsbury</td>\n",
       "      <td>04/01/2022 18:56</td>\n",
       "      <td>804.0</td>\n",
       "      <td>Good's Way, King's Cross</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115895660.0</td>\n",
       "      <td>360.000</td>\n",
       "      <td>19666.0</td>\n",
       "      <td>29/12/2021 16:34</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Calshot Street , King's Cross</td>\n",
       "      <td>29/12/2021 16:28</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Guilford Street , Bloomsbury</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116016563.0</td>\n",
       "      <td>480.000</td>\n",
       "      <td>19861.0</td>\n",
       "      <td>04/01/2022 18:46</td>\n",
       "      <td>804.0</td>\n",
       "      <td>Good's Way, King's Cross</td>\n",
       "      <td>04/01/2022 18:38</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Guilford Street , Bloomsbury</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>116014412.0</td>\n",
       "      <td>1260.000</td>\n",
       "      <td>17235.0</td>\n",
       "      <td>04/01/2022 17:45</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Belgrove Street , King's Cross</td>\n",
       "      <td>04/01/2022 17:24</td>\n",
       "      <td>297.0</td>\n",
       "      <td>Geraldine Street, Elephant &amp; Castle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11232180</th>\n",
       "      <td>127642060.0</td>\n",
       "      <td>1776.354</td>\n",
       "      <td>19859.0</td>\n",
       "      <td>2022-12-26 08:30</td>\n",
       "      <td>672.0</td>\n",
       "      <td>Chicheley Street, South Bank</td>\n",
       "      <td>2022-12-26 08:01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cantrell Road, Bow</td>\n",
       "      <td>127642060.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-12-26 08:30</td>\n",
       "      <td>200206</td>\n",
       "      <td>Chicheley Street, South Bank</td>\n",
       "      <td>19859.0</td>\n",
       "      <td>CLASSIC</td>\n",
       "      <td>29m 36s</td>\n",
       "      <td>1776354.0</td>\n",
       "      <td>Chicheley Street, South Bank</td>\n",
       "      <td>672.0</td>\n",
       "      <td>200206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11232181</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>220.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chelsea Green, Chelsea</td>\n",
       "      <td>220.0</td>\n",
       "      <td>1179.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11232182</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Colombo Street, Southwark</td>\n",
       "      <td>240.0</td>\n",
       "      <td>3472.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11232183</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>363.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lord's, St. John's Wood</td>\n",
       "      <td>363.0</td>\n",
       "      <td>2665.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11232184</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>731.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Michael Road, Walham Green</td>\n",
       "      <td>731.0</td>\n",
       "      <td>300095.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11232185 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Rental Id  Duration  Bike Id          End Date  EndStation Id  \\\n",
       "0         115967515.0  1260.000  15338.0  01/01/2022 23:13          310.0   \n",
       "1         116017034.0   720.000  19861.0  04/01/2022 19:08           11.0   \n",
       "2         115895660.0   360.000  19666.0  29/12/2021 16:34           70.0   \n",
       "3         116016563.0   480.000  19861.0  04/01/2022 18:46          804.0   \n",
       "4         116014412.0  1260.000  17235.0  04/01/2022 17:45           14.0   \n",
       "...               ...       ...      ...               ...            ...   \n",
       "11232180  127642060.0  1776.354  19859.0  2022-12-26 08:30          672.0   \n",
       "11232181          NaN       NaN      NaN               NaN          220.0   \n",
       "11232182          NaN       NaN      NaN               NaN          240.0   \n",
       "11232183          NaN       NaN      NaN               NaN          363.0   \n",
       "11232184          NaN       NaN      NaN               NaN          731.0   \n",
       "\n",
       "                         EndStation Name        Start Date  StartStation Id  \\\n",
       "0            Black Prince Road, Vauxhall  01/01/2022 22:52            529.0   \n",
       "1           Brunswick Square, Bloomsbury  04/01/2022 18:56            804.0   \n",
       "2          Calshot Street , King's Cross  29/12/2021 16:28             57.0   \n",
       "3               Good's Way, King's Cross  04/01/2022 18:38             57.0   \n",
       "4         Belgrove Street , King's Cross  04/01/2022 17:24            297.0   \n",
       "...                                  ...               ...              ...   \n",
       "11232180    Chicheley Street, South Bank  2022-12-26 08:01              NaN   \n",
       "11232181                             NaN               NaN              NaN   \n",
       "11232182                             NaN               NaN              NaN   \n",
       "11232183                             NaN               NaN              NaN   \n",
       "11232184                             NaN               NaN              NaN   \n",
       "\n",
       "                            StartStation Name       Number  ...  \\\n",
       "0                       Manresa Road, Chelsea          NaN  ...   \n",
       "1                    Good's Way, King's Cross          NaN  ...   \n",
       "2                Guilford Street , Bloomsbury          NaN  ...   \n",
       "3                Guilford Street , Bloomsbury          NaN  ...   \n",
       "4         Geraldine Street, Elephant & Castle          NaN  ...   \n",
       "...                                       ...          ...  ...   \n",
       "11232180                   Cantrell Road, Bow  127642060.0  ...   \n",
       "11232181                                  NaN          NaN  ...   \n",
       "11232182                                  NaN          NaN  ...   \n",
       "11232183                                  NaN          NaN  ...   \n",
       "11232184                                  NaN          NaN  ...   \n",
       "\n",
       "                  End date End station number                   End station  \\\n",
       "0                      NaN                NaN                           NaN   \n",
       "1                      NaN                NaN                           NaN   \n",
       "2                      NaN                NaN                           NaN   \n",
       "3                      NaN                NaN                           NaN   \n",
       "4                      NaN                NaN                           NaN   \n",
       "...                    ...                ...                           ...   \n",
       "11232180  2022-12-26 08:30             200206  Chicheley Street, South Bank   \n",
       "11232181               NaN                NaN                           NaN   \n",
       "11232182               NaN                NaN                           NaN   \n",
       "11232183               NaN                NaN                           NaN   \n",
       "11232184               NaN                NaN                           NaN   \n",
       "\n",
       "         Bike number Bike model Total duration  Total duration (ms)  \\\n",
       "0                NaN        NaN            NaN                  NaN   \n",
       "1                NaN        NaN            NaN                  NaN   \n",
       "2                NaN        NaN            NaN                  NaN   \n",
       "3                NaN        NaN            NaN                  NaN   \n",
       "4                NaN        NaN            NaN                  NaN   \n",
       "...              ...        ...            ...                  ...   \n",
       "11232180     19859.0    CLASSIC        29m 36s            1776354.0   \n",
       "11232181         NaN        NaN            NaN                  NaN   \n",
       "11232182         NaN        NaN            NaN                  NaN   \n",
       "11232183         NaN        NaN            NaN                  NaN   \n",
       "11232184         NaN        NaN            NaN                  NaN   \n",
       "\n",
       "                                  name     id  terminal name  \n",
       "0                                  NaN    NaN            NaN  \n",
       "1                                  NaN    NaN            NaN  \n",
       "2                                  NaN    NaN            NaN  \n",
       "3                                  NaN    NaN            NaN  \n",
       "4                                  NaN    NaN            NaN  \n",
       "...                                ...    ...            ...  \n",
       "11232180  Chicheley Street, South Bank  672.0       200206.0  \n",
       "11232181        Chelsea Green, Chelsea  220.0         1179.0  \n",
       "11232182     Colombo Street, Southwark  240.0         3472.0  \n",
       "11232183       Lord's, St. John's Wood  363.0         2665.0  \n",
       "11232184    Michael Road, Walham Green  731.0       300095.0  \n",
       "\n",
       "[11232185 rows x 23 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2022_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the last three columns from the dataframe \n",
    "data_2022_clean = data_2022_clean.drop(columns=['id', 'name', 'terminal name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join tables by start station name\n",
    "data_2022_clean = pd.merge(data_2022_clean, df_id, left_on='Start station', right_on='name', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populating 'StartStation Id'\n",
    "data_2022_clean.loc[data_2022_clean['StartStation Id'].isnull(), 'StartStation Id'] = data_2022_clean['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rental Id                    28\n",
       "Duration                     28\n",
       "Bike Id                      28\n",
       "End Date                     28\n",
       "EndStation Id            332434\n",
       "EndStation Name              28\n",
       "Start Date                   28\n",
       "StartStation Id           35142\n",
       "StartStation Name            28\n",
       "Number                  8677132\n",
       "Start date              8677132\n",
       "Start station number    8677132\n",
       "Start station           8677132\n",
       "End date                8677132\n",
       "End station number      8677132\n",
       "End station             8677132\n",
       "Bike number             8677132\n",
       "Bike model              8677132\n",
       "Total duration          8677132\n",
       "Total duration (ms)     8677132\n",
       "name                    8713108\n",
       "id                      8713108\n",
       "terminal name           8713108\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summerising the remaing null values \n",
    "# it's look a lot better but there's still quite a few EndStation Ids and StartStation Ids with null values \n",
    "data_2022_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wellington Street , Strand            6296\n",
      "Leonard Circus , Shoreditch           5066\n",
      "Jubilee Gardens, South Bank           4990\n",
      "Southampton Street, Strand            4227\n",
      "Jubilee Plaza, Canary Wharf           4173\n",
      "Chesilton Road, Fulham                3403\n",
      "Bruton Street, Mayfair                2289\n",
      "Coomer Place, West Kensington_OLD     1940\n",
      "Abyssinia Close, Clapham Junction     1614\n",
      "New North Road 1, Hoxton              1115\n",
      "One London                               4\n",
      "Hammersmith Town Hall, Hammersmith       1\n",
      "Name: StartStation Name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# sum of null ids by start station\n",
    "print(data_2022_clean.loc[data_2022_clean['StartStation Id'].isnull(), 'StartStation Name'].value_counts())\n",
    "# sum of null ids by end station\n",
    "print(data_2022_clean.loc[data_2022_clean['EndStation Id'].isnull(), 'EndStation Name'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some docking stations have closed, as per the tfl website, https://tfl.gov.uk/modes/cycling/santander-cycles/docking-stations\n",
    "\n",
    "# we will leave this for now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping unwanted columns from the 2022 data frame\n",
    "data_2022 = data_2022_clean.drop(columns=['Number', 'Start date', 'Start station number', 'Start station', 'End date',\n",
    "                                                'End station number', 'End station', 'Bike number', 'Bike model', 'Total duration', \n",
    "                                                'Total duration (ms)', 'id', 'name', 'terminal name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rental Id</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Bike Id</th>\n",
       "      <th>End Date</th>\n",
       "      <th>EndStation Id</th>\n",
       "      <th>EndStation Name</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>StartStation Id</th>\n",
       "      <th>StartStation Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115967515.0</td>\n",
       "      <td>1260.000</td>\n",
       "      <td>15338.0</td>\n",
       "      <td>01/01/2022 23:13</td>\n",
       "      <td>310.0</td>\n",
       "      <td>Black Prince Road, Vauxhall</td>\n",
       "      <td>01/01/2022 22:52</td>\n",
       "      <td>529.0</td>\n",
       "      <td>Manresa Road, Chelsea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>116017034.0</td>\n",
       "      <td>720.000</td>\n",
       "      <td>19861.0</td>\n",
       "      <td>04/01/2022 19:08</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Brunswick Square, Bloomsbury</td>\n",
       "      <td>04/01/2022 18:56</td>\n",
       "      <td>804.0</td>\n",
       "      <td>Good's Way, King's Cross</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115895660.0</td>\n",
       "      <td>360.000</td>\n",
       "      <td>19666.0</td>\n",
       "      <td>29/12/2021 16:34</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Calshot Street , King's Cross</td>\n",
       "      <td>29/12/2021 16:28</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Guilford Street , Bloomsbury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116016563.0</td>\n",
       "      <td>480.000</td>\n",
       "      <td>19861.0</td>\n",
       "      <td>04/01/2022 18:46</td>\n",
       "      <td>804.0</td>\n",
       "      <td>Good's Way, King's Cross</td>\n",
       "      <td>04/01/2022 18:38</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Guilford Street , Bloomsbury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>116014412.0</td>\n",
       "      <td>1260.000</td>\n",
       "      <td>17235.0</td>\n",
       "      <td>04/01/2022 17:45</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Belgrove Street , King's Cross</td>\n",
       "      <td>04/01/2022 17:24</td>\n",
       "      <td>297.0</td>\n",
       "      <td>Geraldine Street, Elephant &amp; Castle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11232204</th>\n",
       "      <td>127137507.0</td>\n",
       "      <td>171.717</td>\n",
       "      <td>90223.0</td>\n",
       "      <td>2022-11-28 14:51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>One London</td>\n",
       "      <td>2022-11-28 14:48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>One London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11232205</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>220.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11232206</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11232207</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>363.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11232208</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>731.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11232209 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Rental Id  Duration  Bike Id          End Date  EndStation Id  \\\n",
       "0         115967515.0  1260.000  15338.0  01/01/2022 23:13          310.0   \n",
       "1         116017034.0   720.000  19861.0  04/01/2022 19:08           11.0   \n",
       "2         115895660.0   360.000  19666.0  29/12/2021 16:34           70.0   \n",
       "3         116016563.0   480.000  19861.0  04/01/2022 18:46          804.0   \n",
       "4         116014412.0  1260.000  17235.0  04/01/2022 17:45           14.0   \n",
       "...               ...       ...      ...               ...            ...   \n",
       "11232204  127137507.0   171.717  90223.0  2022-11-28 14:51            NaN   \n",
       "11232205          NaN       NaN      NaN               NaN          220.0   \n",
       "11232206          NaN       NaN      NaN               NaN          240.0   \n",
       "11232207          NaN       NaN      NaN               NaN          363.0   \n",
       "11232208          NaN       NaN      NaN               NaN          731.0   \n",
       "\n",
       "                         EndStation Name        Start Date  StartStation Id  \\\n",
       "0            Black Prince Road, Vauxhall  01/01/2022 22:52            529.0   \n",
       "1           Brunswick Square, Bloomsbury  04/01/2022 18:56            804.0   \n",
       "2          Calshot Street , King's Cross  29/12/2021 16:28             57.0   \n",
       "3               Good's Way, King's Cross  04/01/2022 18:38             57.0   \n",
       "4         Belgrove Street , King's Cross  04/01/2022 17:24            297.0   \n",
       "...                                  ...               ...              ...   \n",
       "11232204                      One London  2022-11-28 14:48              NaN   \n",
       "11232205                             NaN               NaN              NaN   \n",
       "11232206                             NaN               NaN              NaN   \n",
       "11232207                             NaN               NaN              NaN   \n",
       "11232208                             NaN               NaN              NaN   \n",
       "\n",
       "                            StartStation Name  \n",
       "0                       Manresa Road, Chelsea  \n",
       "1                    Good's Way, King's Cross  \n",
       "2                Guilford Street , Bloomsbury  \n",
       "3                Guilford Street , Bloomsbury  \n",
       "4         Geraldine Street, Elephant & Castle  \n",
       "...                                       ...  \n",
       "11232204                           One London  \n",
       "11232205                                  NaN  \n",
       "11232206                                  NaN  \n",
       "11232207                                  NaN  \n",
       "11232208                                  NaN  \n",
       "\n",
       "[11232209 rows x 9 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data '2022-09-18 23:59' does not match format '%d/%m/%Y %H:%M' (match)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# cleaning the 2022 data following the same process\u001b[39;00m\n\u001b[0;32m      2\u001b[0m data_2022[\u001b[39m'\u001b[39m\u001b[39mStart Date\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39m data_2022[\u001b[39m'\u001b[39m\u001b[39mStart Date\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstr[:\u001b[39m16\u001b[39m]\n\u001b[1;32m----> 4\u001b[0m data_2022[\u001b[39m'\u001b[39m\u001b[39mStart Date Converted\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mto_datetime(data_2022[\u001b[39m'\u001b[39;49m\u001b[39mStart Date\u001b[39;49m\u001b[39m'\u001b[39;49m], \u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mformat\u001b[39;49m)\u001b[39m.\u001b[39mdt\u001b[39m.\u001b[39mdate\n\u001b[0;32m      6\u001b[0m data_2022[\u001b[39m'\u001b[39m\u001b[39mHours\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(data_2022[\u001b[39m'\u001b[39m\u001b[39mStart Date\u001b[39m\u001b[39m'\u001b[39m], \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39mformat\u001b[39m)\u001b[39m.\u001b[39mdt\u001b[39m.\u001b[39mhour\n\u001b[0;32m      8\u001b[0m data_2022[\u001b[39m'\u001b[39m\u001b[39mDay\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(data_2022[\u001b[39m'\u001b[39m\u001b[39mStart Date\u001b[39m\u001b[39m'\u001b[39m], \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39mformat\u001b[39m)\u001b[39m.\u001b[39mdt\u001b[39m.\u001b[39mweekday\n",
      "File \u001b[1;32mc:\\Users\\EMoses\\miniconda3\\envs\\diss\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1068\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1066\u001b[0m         result \u001b[39m=\u001b[39m arg\u001b[39m.\u001b[39mmap(cache_array)\n\u001b[0;32m   1067\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1068\u001b[0m         values \u001b[39m=\u001b[39m convert_listlike(arg\u001b[39m.\u001b[39;49m_values, \u001b[39mformat\u001b[39;49m)\n\u001b[0;32m   1069\u001b[0m         result \u001b[39m=\u001b[39m arg\u001b[39m.\u001b[39m_constructor(values, index\u001b[39m=\u001b[39marg\u001b[39m.\u001b[39mindex, name\u001b[39m=\u001b[39marg\u001b[39m.\u001b[39mname)\n\u001b[0;32m   1070\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[39m.\u001b[39mMutableMapping)):\n",
      "File \u001b[1;32mc:\\Users\\EMoses\\miniconda3\\envs\\diss\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:430\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    427\u001b[0m         \u001b[39mformat\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    429\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mformat\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 430\u001b[0m     res \u001b[39m=\u001b[39m _to_datetime_with_format(\n\u001b[0;32m    431\u001b[0m         arg, orig_arg, name, tz, \u001b[39mformat\u001b[39;49m, exact, errors, infer_datetime_format\n\u001b[0;32m    432\u001b[0m     )\n\u001b[0;32m    433\u001b[0m     \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    434\u001b[0m         \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mc:\\Users\\EMoses\\miniconda3\\envs\\diss\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:538\u001b[0m, in \u001b[0;36m_to_datetime_with_format\u001b[1;34m(arg, orig_arg, name, tz, fmt, exact, errors, infer_datetime_format)\u001b[0m\n\u001b[0;32m    535\u001b[0m         \u001b[39mreturn\u001b[39;00m _box_as_indexlike(result, utc\u001b[39m=\u001b[39mutc, name\u001b[39m=\u001b[39mname)\n\u001b[0;32m    537\u001b[0m \u001b[39m# fallback\u001b[39;00m\n\u001b[1;32m--> 538\u001b[0m res \u001b[39m=\u001b[39m _array_strptime_with_fallback(\n\u001b[0;32m    539\u001b[0m     arg, name, tz, fmt, exact, errors, infer_datetime_format\n\u001b[0;32m    540\u001b[0m )\n\u001b[0;32m    541\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mc:\\Users\\EMoses\\miniconda3\\envs\\diss\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:473\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[1;34m(arg, name, tz, fmt, exact, errors, infer_datetime_format)\u001b[0m\n\u001b[0;32m    470\u001b[0m utc \u001b[39m=\u001b[39m tz \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mutc\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    472\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 473\u001b[0m     result, timezones \u001b[39m=\u001b[39m array_strptime(arg, fmt, exact\u001b[39m=\u001b[39;49mexact, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m    474\u001b[0m \u001b[39mexcept\u001b[39;00m OutOfBoundsDatetime:\n\u001b[0;32m    475\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\EMoses\\miniconda3\\envs\\diss\\lib\\site-packages\\pandas\\_libs\\tslibs\\strptime.pyx:150\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: time data '2022-09-18 23:59' does not match format '%d/%m/%Y %H:%M' (match)"
     ]
    }
   ],
   "source": [
    "# cleaning the 2022 data following the same process\n",
    "data_2022['Start Date']= data_2022['Start Date'].str[:16]\n",
    "\n",
    "data_2022['Start Date Converted']= pd.to_datetime(data_2022['Start Date'], format=format).dt.date\n",
    "\n",
    "data_2022['Hours']= pd.to_datetime(data_2022['Start Date'], format=format).dt.hour\n",
    "\n",
    "data_2022['Day']= pd.to_datetime(data_2022['Start Date'], format=format).dt.weekday\n",
    "\n",
    "data_2022.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the date column to datetime format\n",
    "data_2019['Start Date Converted'] = pd.to_datetime(data_2019['Start Date Converted'])\n",
    "#data_2022['Start Date Converted'] = pd.to_datetime(data_2022['Start Date Converted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10310063, 12)\n"
     ]
    }
   ],
   "source": [
    "# Filter the dataframe to only include data from 2019\n",
    "# Remember, one of the merged csv files contain data between 26/12/2018 to 01/01/2019 - filtering will remove the 2018 data \n",
    "bike_data_2019 = data_2019[data_2019['Start Date Converted'].dt.year == 2019]\n",
    "print(bike_data_2019.shape)\n",
    "\n",
    "# 2022 filtering data\n",
    "#bike_data_2022 = data_2022[data_2022['Start Date Converted'].dt.year == 2022]\n",
    "#print(bike_data_2022.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing data in an SQL databse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# psycopg2 library installed to connect to a PostgreSQL database from Python\n",
    "\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connection to postgres database\n",
    "conn = psycopg2.connect(\n",
    "    user=\"postgres\",\n",
    "    password=\"password123\",\n",
    "    host=\"localhost\",\n",
    "    database=\"diss_data\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SQLAlchemy engine: Create a SQLAlchemy engine using the create_engine function, which will be used to write the DataFrame to the database.\n",
    "engine = create_engine('postgresql+psycopg2://postgres:password123@localhost:5432/diss_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export the DataFrame to the database: Once you have the connection and engine set up, you can use the to_sql method of the DataFrame to export it to the database.\n",
    "# save the DataFrame to the PostgreSQL database\n",
    "# set the index parameter to False to avoid saving the DataFrame's index as a separate column in the database.\n",
    "bike_data_2019.to_sql('bike_data_2019_tb', engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "249cc518374e28bf1fa10a0460f1501eab88ca4f883968af225d88dc54cdfb38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
